{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPe2QgzGYzieWGbZidULd+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuizzzM/-01GIT/blob/main/hidra_multimodal_testbed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß† Hidra Gemini Cygnus Testbed\n",
        "\n",
        "Este notebook apresenta o ambiente de testes do sistema **Hidra**, uma arquitetura de intelig√™ncia artificial multimodal desenvolvida no IFNMG ‚Äì Campus Salinas. A vers√£o atual integra modelos avan√ßados como **Gemini Cygnus**, **Meta-Llama Instruct**, **Whisper**, **FER+**, e m√≥dulos visuais e interativos via **Streamlit**.\n",
        "\n",
        "## üéØ Objetivos\n",
        "- Testar e validar a integra√ß√£o de modelos multimodais\n",
        "- Realizar auditorias √©ticas e infer√™ncias emocionais\n",
        "- Simular cen√°rios institucionais com entrada de voz, imagem e texto\n",
        "\n",
        "## üß∞ Componentes Principais\n",
        "- **HidraText**: Gera√ß√£o de texto explicativo com Meta-Llama\n",
        "- **HidraVision**: Classifica√ß√£o e processamento de imagens\n",
        "- **Whisper**: Transcri√ß√£o e an√°lise de voz\n",
        "- **FER+**: Reconhecimento de emo√ß√µes faciais\n",
        "- **Cygnus**: An√°lise preditiva com otimiza√ß√£o avan√ßada\n",
        "\n",
        "---\n",
        "\n",
        "> üí° Este notebook √© um _testbed_ modular e escal√°vel, ideal para experimenta√ß√µes acad√™micas e institucionais com IA √©tica e acess√≠vel."
      ],
      "metadata": {
        "id": "CKsPIzwXiHys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sistema Hidra ‚Äì IA Multimodal com Modelos Hidra\n",
        "\n",
        "Introdu√ß√£o\n",
        "\n",
        "O projeto Hidra √© uma iniciativa acad√™mica desenvolvida no Instituto Federal do Norte de Minas Gerais, com o objetivo de criar um sistema de intelig√™ncia artificial multimodal robusto e √©tico. Este sistema √© baseado na arquitetura Hidra de Luiz Augusto Mendes Barbosa.\n",
        "Conhecida por sua modularidade, transpar√™ncia e compatibilidade com execu√ß√£o local.\n",
        "\n",
        "Refer√™ncias T√©cnicas\n",
        "\n",
        "Modelos Granite: A base do sistema Hidra, incluindo Hidra Vision, Hidra Instruct e Hidra Guardian, que oferecem suporte a tarefas como classifica√ß√£o de imagens, gera√ß√£o de texto e auditoria √©tica.\n",
        "\n",
        "Hugging Face Transformers: Biblioteca amplamente utilizada para implementar modelos de aprendizado profundo em tarefas de NLP, vis√£o computacional e multimodalidade.\n",
        "\n",
        "Whisper: Modelo de transcri√ß√£o de √°udio desenvolvido pela OpenAI, integrado ao Hidra para an√°lise de voz.\n",
        "\n",
        "FER+: Ferramenta para reconhecimento de emo√ß√µes faciais, utilizada para infer√™ncia emocional.\n",
        "\n",
        "Streamlit e Widgets: Tecnologias para criar interfaces interativas e pain√©is de visualiza√ß√£o.\n",
        "\n",
        "O sistema Hidra √© projetado para aplica√ß√µes educacionais, institucionais e √©ticas, com foco em acessibilidade, explicabilidade e responsabilidade.\n"
      ],
      "metadata": {
        "id": "ifSkkHaeRUND"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N7V-quARA5j"
      },
      "outputs": [],
      "source": [
        "# Sistema Hidra ‚Äì IA\n",
        "**Discente:** Luiz Augusto Mendes Barbosa\n",
        "**Institui√ß√£o:** Instituto Federal do Norte de Minas Gerais ‚Äì Campus Salinas\n",
        "**Curso:** Bacharelado em Sistemas De Informa√ß√£o\n",
        "**Data:** Agosto de 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explica√ß√£o T√©cnica\n",
        "\n",
        "Este bloco de c√≥digo instala as bibliotecas necess√°rias para o funcionamento do sistema Hidra.\n",
        "\n",
        "Transformers: Biblioteca essencial para carregar e utilizar modelos pr√©-treinados, como os da fam√≠lia\n",
        "\n",
        "Hidra\n",
        "\n",
        ".\n",
        "\n",
        "FER: Ferramenta para reconhecimento de emo√ß√µes faciais, integrada ao m√≥dulo de infer√™ncia emocional.\n",
        "\n",
        "Streamlit: Utilizada para criar interfaces interativas e pain√©is de visualiza√ß√£o.\n",
        "\n",
        "Whisper: Modelo de transcri√ß√£o de √°udio, crucial para o m√≥dulo de an√°lise de voz.\n",
        "\n",
        "OpenAI: Biblioteca para integra√ß√£o com modelos avan√ßados de IA.\n",
        "\n",
        "Pillow e OpenCV: Ferramentas para manipula√ß√£o e processamento de imagens, utilizadas no m√≥dulo Hidra Vision.\n",
        "\n",
        "Certifique-se de executar este comando em um ambiente Python com acesso √† internet para garantir a instala√ß√£o bem-sucedida."
      ],
      "metadata": {
        "id": "5xT9Utb3Rlpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers fer streamlit whisper openai pillow opencv-python"
      ],
      "metadata": {
        "id": "4b6YnAyQTyS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54532634-1ece-4e47-d05c-66d17b2b2c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.1)\n",
            "Collecting fer\n",
            "  Downloading fer-22.5.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.47.1)\n",
            "Collecting whisper\n",
            "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.97.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from fer) (3.10.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from fer) (4.12.0.88)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fer) (3.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from fer) (2.2.2)\n",
            "Collecting facenet-pytorch (from fer)\n",
            "  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (from fer) (1.0.3)\n",
            "Collecting ffmpeg==1.4 (from fer)\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from whisper) (1.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=2.0.0->fer) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=2.0.0->fer) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=2.0.0->fer) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=2.0.0->fer) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=2.0.0->fer) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=2.0.0->fer) (0.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->fer) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->fer) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->fer) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "INFO: pip is looking at multiple versions of facenet-pytorch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting facenet-pytorch (from fer)\n",
            "  Downloading facenet_pytorch-2.5.3-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch->fer) (0.21.0+cu124)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fer) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fer) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fer) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fer) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fer) (3.2.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy->fer) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy->fer) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy->fer) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy->fer) (0.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.0.0->fer) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.0.0->fer) (2.19.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->facenet-pytorch->fer) (2.6.0+cu124)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision->facenet-pytorch->fer) (3.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision->facenet-pytorch->fer) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision->facenet-pytorch->fer) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision->facenet-pytorch->fer) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision->facenet-pytorch->fer) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision->facenet-pytorch->fer) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision->facenet-pytorch->fer) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.0.0->fer) (0.1.2)\n",
            "Downloading fer-22.5.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m762.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ffmpeg, whisper\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=ce97e7cd96b75159016ec8c26bba09dcee25c9274ad0b84625b9ef33c573a31b\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/30/c5/576bdd729f3bc062d62a551be7fefd6ed2f761901568171e4e\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41120 sha256=0cf0d6c74ed1a24c40e694b20e9f3453368f51156d5cf7f22540624b5a2e88e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/65/ee/4e6672aabfa486d3341a39a04f8f87c77e5156149299b5a7d0\n",
            "Successfully built ffmpeg whisper\n",
            "Installing collected packages: ffmpeg, whisper, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, facenet-pytorch, fer\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed facenet-pytorch-2.5.3 fer-22.5.1 ffmpeg-1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 whisper-1.1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CGL3yT1ZJqno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HidraText ‚Äì Gera√ß√£o de Texto Explicativo\n",
        "\n",
        "Explica√ß√£o T√©cnica\n",
        "\n",
        "O modelo Meta-Llama Instruct √© um LLM (Large Language Model) projetado para tarefas de gera√ß√£o de texto e racioc√≠nio.\n",
        "\n",
        "Hist√≥ria do Modelo: Desenvolvido pela Meta, o Meta-Llama Instruct √© otimizado para fornecer respostas explicativas e detalhadas, com foco em √©tica e aplicabilidade pr√°tica.\n",
        "\n",
        "Funcionamento: O modelo utiliza um prompt para gerar texto baseado em aprendizado profundo.\n",
        "\n",
        "Aplica√ß√£o no Hidra: Este modelo √© utilizado para criar explica√ß√µes detalhadas e relat√≥rios t√©cnicos, como auditorias √©ticas e an√°lises de impacto.\n",
        "\n",
        "O c√≥digo abaixo demonstra como carregar o modelo, preparar um prompt e gerar uma resposta. Certifique-se de que o ambiente Python tenha acesso √† internet para baixar os pesos do modelo."
      ],
      "metadata": {
        "id": "YG1rTenwSMAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "prompt = \"Explique os riscos √©ticos do uso de IA em ambientes escolares.\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = model.generate(**inputs, max_new_tokens=250)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "LIK_Ok7BSP3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° Certifique-se de que o ambiente Python tenha acesso √† internet para baixar os pesos do modelo."
      ],
      "metadata": {
        "id": "y4AUt8UKj00r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üõ°Ô∏è Hidra Guardian ‚Äì Auditoria √âtica Automatizada\n",
        "Este m√≥dulo realiza uma verifica√ß√£o simples e eficaz de riscos √©ticos em textos gerados ou recebidos pelo sistema.\n",
        "\n",
        "‚öôÔ∏è Como Funciona\n",
        "- Analisa o conte√∫do textual em busca de termos sens√≠veis como:\n",
        "- \"emo√ß√£o\"\n",
        "- \"consentimento\"\n",
        "- Se encontrar esses termos, sinaliza um poss√≠vel risco √©tico\n",
        "- Recomenda supervis√£o humana para decis√µes cr√≠ticas\n",
        "\n",
        "üß™ Exemplo de C√≥digo\n"
      ],
      "metadata": {
        "id": "Fnj-McK-SR-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simular_auditoria(prompt_texto):\n",
        "    if \"emo√ß√£o\" in prompt_texto.lower() or \"consentimento\" in prompt_texto.lower():\n",
        "        print(\"‚ö†Ô∏è Risco √©tico detectado: Recomenda-se supervis√£o humana.\")\n",
        "    else:\n",
        "        print(\"‚úÖ Entrada validada: sem risco identificado.\")\n",
        "\n",
        "simular_auditoria(\"A IA pode monitorar emo√ß√µes sem consentimento?\")"
      ],
      "metadata": {
        "id": "pgJYtxTsSVN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Aplica√ß√£o no Sistema Hidra\n",
        "- Pode ser integrado a qualquer m√≥dulo que gere ou analise texto\n",
        "- Funciona como uma camada de seguran√ßa √©tica\n",
        "- Ideal para ambientes educacionais e institucionais que exigem responsabilidade no uso de IA\n"
      ],
      "metadata": {
        "id": "nEcUjhpDk289"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üñºÔ∏è Granite Vision ‚Äì Classifica√ß√£o de Imagem\n",
        "Este m√≥dulo utiliza o modelo Granite Vision da IBM para identificar o conte√∫do de imagens por meio de aprendizado profundo.\n",
        "\n",
        "‚öôÔ∏è Como Funciona\n",
        "- Carrega uma imagem da internet\n",
        "- Processa a imagem com um modelo pr√©-treinado\n",
        "- Retorna a classe prevista com base nos dados visuais\n",
        "\n",
        "üß™ Exemplo de C√≥digo\n"
      ],
      "metadata": {
        "id": "LZa0eyYLSZ8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor, AutoModelForImageClassification\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "model_id = \"IBM/granite-vision-3.2-2b\"\n",
        "image = Image.open(requests.get(\"https://images.unsplash.com/photo-1607746882042-944635dfe10e\", stream=True).raw)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "model = AutoModelForImageClassification.from_pretrained(model_id)\n",
        "\n",
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "print(\"üñºÔ∏è Classe prevista:\", outputs.logits.argmax().item())"
      ],
      "metadata": {
        "id": "O2n_W2THSf8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéôÔ∏è Whisper ‚Äì Transcri√ß√£o de √Åudio e An√°lise de Voz\n",
        "\n",
        "O modelo Whisper, desenvolvido pela OpenAI, √© uma ferramenta avan√ßada para transformar fala em texto com alta precis√£o.\n",
        "üß† Caracter√≠sticas\n",
        "- Suporte a m√∫ltiplos idiomas\n",
        "- Funciona bem mesmo em √°udios com ru√≠do\n",
        "- Gera transcri√ß√µes com pontua√ß√£o e formata√ß√£o b√°sica\n",
        "\n",
        "üß© Aplica√ß√£o no Sistema Hidra\n",
        "- Cria√ß√£o de transcri√ß√µes autom√°ticas\n",
        "- An√°lise de entrada auditiva para complementar vis√£o e emo√ß√£o\n",
        "- Ideal para acessibilidade e inclus√£o educacional\n",
        "\n",
        "üß™ Exemplo de C√≥digo\n"
      ],
      "metadata": {
        "id": "98-CvMyBSjGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "modelo = whisper.load_model(\"base\")\n",
        "resultado = modelo.transcribe(\"caminho_para_audio.wav\")\n",
        "print(\"üó£Ô∏è Transcri√ß√£o:\", resultado[\"text\"])"
      ],
      "metadata": {
        "id": "eoytgYBcSlWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FER+ ‚Äì Infer√™ncia Emocional Baseada em Imagens\n",
        "\n",
        "O m√≥dulo FER+ (Facial Emotion Recognition Plus) permite identificar express√µes faciais e classific√°-las em categorias emocionais, como felicidade, tristeza, surpresa e raiva.\n",
        "\n",
        "Funcionalidades\n",
        "\n",
        "Detectar emo√ß√µes em imagens est√°ticas ou v√≠deo.\n",
        "\n",
        "Usar landmarks faciais e classificadores treinados.\n",
        "\n",
        "Suporte a integra√ß√£o com vis√£o computacional e interfaces interativas.\n",
        "\n",
        "Benef√≠cios Institucionais\n",
        "\n",
        "Possibilita estudos sobre empatia computacional.\n",
        "\n",
        "Apoia aplica√ß√µes educacionais inclusivas e centradas no usu√°rio.\n",
        "\n",
        "Pode ser combinado com an√°lise de voz para infer√™ncia multimodal.\n",
        "\n",
        "Observa√ß√£o\n",
        "\n",
        "O modelo FER+ √© acessado via a biblioteca fer, que utiliza algoritmos baseados em aprendizado profundo para infer√™ncia facial."
      ],
      "metadata": {
        "id": "TAzctHY8Spuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fer import FER\n",
        "import cv2\n",
        "\n",
        "imagem = cv2.imread(\"expressao_usuario.jpg\")\n",
        "detector = FER(mtcnn=True)\n",
        "emocao = detector.detect_emotions(imagem)\n",
        "print(\"üòä Emo√ß√µes detectadas:\", emocao)"
      ],
      "metadata": {
        "id": "0iG5BCaNSrRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Hidra Operator ‚Äì Racioc√≠nio L√≥gico com Transformers\n",
        "Este m√≥dulo utiliza um modelo especializado em racioc√≠nio l√≥gico para gerar sugest√µes baseadas em texto.\n",
        "\n",
        "‚öôÔ∏è Como Funciona\n",
        "- Recebe uma frase como entrada\n",
        "- Classifica a inten√ß√£o ou l√≥gica por tr√°s do texto\n",
        "- Retorna uma classe que representa a sugest√£o l√≥gica\n",
        "\n",
        "üß™ Exemplo de C√≥digo\n"
      ],
      "metadata": {
        "id": "6ADNI2WTSujP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_id = \"Operator/logic-integration-1b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
        "\n",
        "inputs = tokenizer(\"Analise os dados e gere sugest√µes.\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "print(\"üîç Sugest√£o l√≥gica (classe):\", outputs.logits.argmax().item())"
      ],
      "metadata": {
        "id": "2J4PqqpmSx-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° Ideal para an√°lises institucionais, tomada de decis√£o e simula√ß√µes de racioc√≠nio."
      ],
      "metadata": {
        "id": "JDSEHXEsoT3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß© Interface Interativa com Widgets\n",
        "Este m√≥dulo permite criar interfaces simples e funcionais para entrada de texto no notebook.\n",
        "\n",
        "üß™ Exemplo de C√≥digo\n"
      ],
      "metadata": {
        "id": "PYQ9Pdk3S0P5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "entrada = widgets.Text(value='', placeholder='Digite sua pergunta', description='Pergunta:')\n",
        "display(entrada)"
      ],
      "metadata": {
        "id": "DURgw8nhS3xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìÇ 11. Upload de Arquivos\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "XP_T8rtuouG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "-sAfNL92l_I8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìò 12. Conclus√£o\n",
        "\n",
        "O projeto Hidra representa um avan√ßo significativo na pesquisa e desenvolvimento de sistemas de intelig√™ncia artificial multimodal, com foco em √©tica, acessibilidade e aplicabilidade educacional.\n",
        "üåê Impacto Tecnol√≥gico\n",
        "- Integra modelos de ponta como Granite, Whisper, FER+, e Cygnus, cobrindo linguagem, vis√£o, voz e emo√ß√£o.\n",
        "- Utiliza arquitetura modular e escal√°vel, permitindo testes independentes e integra√ß√£o fluida entre componentes.\n",
        "üß† Inova√ß√£o Acad√™mica\n",
        "- Promove o uso de IA em ambientes escolares e institucionais com responsabilidade e transpar√™ncia.\n",
        "- Estimula o pensamento cr√≠tico sobre o papel da tecnologia na educa√ß√£o e na forma√ß√£o √©tica dos usu√°rios.\n",
        "üõ°Ô∏è Responsabilidade e √âtica\n",
        "- M√≥dulos como Hidra Guardian e Hidra Ethica garantem que o sistema opere com supervis√£o √©tica e respeito √† privacidade.\n",
        "- A infer√™ncia emocional e a transcri√ß√£o de voz s√£o aplicadas com foco em inclus√£o e empatia computacional.\n",
        "üìà Pr√≥ximos Passos\n",
        "- Valida√ß√£o T√©cnica: Testar todos os m√≥dulos com dados reais e cen√°rios simulados.\n",
        "- Documenta√ß√£o Expandida: Criar guias de uso e tutoriais para facilitar a ado√ß√£o por outros pesquisadores.\n",
        "- Interface Final: Desenvolver um painel interativo com Streamlit para demonstra√ß√£o p√∫blica.\n",
        "- Publica√ß√£o Cient√≠fica: Consolidar os resultados em um artigo t√©cnico\n"
      ],
      "metadata": {
        "id": "ti5IqTfeS-H4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "2pfD2bAATDTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üì¶ Instala√ß√£o de Bibliotecas"
      ],
      "metadata": {
        "id": "mUsGJgDtYfSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers fer streamlit whisper openai pillow opencv-python matplotlib seaborn"
      ],
      "metadata": {
        "id": "4QVr4sddZgQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üõ†Ô∏è Fun√ß√£o para Gerar Notebook Din√¢mico"
      ],
      "metadata": {
        "id": "WV3XTPtWZsty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nbformat import v4 as nbf\n",
        "import os\n",
        "\n",
        "def criar_notebook(nome=\"Relatorio_Hidra\"):\n",
        "    notebook = nbf.new_notebook()\n",
        "\n",
        "    # C√©lula de introdu√ß√£o\n",
        "    intro = nbf.new_markdown_cell(\"# Relat√≥rio Autom√°tico do Sistema Hidra\\nEste notebook foi gerado automaticamente com os resultados dos m√≥dulos multimodais.\")\n",
        "\n",
        "    # C√©lula de importa√ß√µes\n",
        "    imports = nbf.new_code_cell(\"\"\"import matplotlib.pyplot as plt\\nimport seaborn as sns\\nimport pandas as pd\"\"\")\n",
        "\n",
        "    # C√©lula de resultados de √°udio\n",
        "    audio_result = nbf.new_code_cell(\"\"\"# Resultado do m√≥dulo Whisper\\nprint('Transcri√ß√£o de √°udio: ...')\"\"\")\n",
        "\n",
        "    # C√©lula de emo√ß√µes\n",
        "    emocao_result = nbf.new_code_cell(\"\"\"# Resultado do m√≥dulo FER+\\nprint('Emo√ß√£o detectada: ...')\"\"\")\n",
        "\n",
        "    # C√©lula de gera√ß√£o de texto\n",
        "    texto_result = nbf.new_code_cell(\"\"\"# Resultado do m√≥dulo Hidra Instruct\\nprint('Texto gerado: ...')\"\"\")\n",
        "\n",
        "    # C√©lula de an√°lise preditiva\n",
        "    cygnus_result = nbf.new_code_cell(\"\"\"# Resultado do m√≥dulo Cygnus\\nprint('An√°lise preditiva: ...')\"\"\")\n",
        "\n",
        "    # C√©lula de conclus√£o\n",
        "    conclusao = nbf.new_markdown_cell(\"## Conclus√£o\\nEste relat√≥rio consolida os dados multimodais processados pelo sistema Hidra, promovendo explicabilidade e responsabilidade.\")\n",
        "\n",
        "    # Adiciona todas as c√©lulas\n",
        "    notebook.cells = [intro, imports, audio_result, emocao_result, texto_result, cygnus_result, conclusao]\n",
        "\n",
        "    # Salva o notebook\n",
        "    with open(f\"{nome}.ipynb\", \"w\", encoding=\"utf-8\") as f:\n",
        "        nbf.write(notebook, f)\n",
        "\n",
        "    print(f\"Notebook '{nome}.ipynb' criado com sucesso.\")"
      ],
      "metadata": {
        "id": "7-bifo3qZupB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìò Estrutura do Notebook Colab ‚Äì Integra√ß√£o do Sistema Hidra\n",
        "\n",
        " üîß 1. Instala√ß√£o de Bibliotecas"
      ],
      "metadata": {
        "id": "6AHN9PfhZ09_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers fer whisper openai pillow opencv-python matplotlib seaborn requests"
      ],
      "metadata": {
        "id": "FxIl6PkMaBxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† 2. M√≥dulo Cygnus ‚Äì Execu√ß√£o Preditiva"
      ],
      "metadata": {
        "id": "pTPAbjKkaEfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gemini import AdvancedModel\n",
        "\n",
        "# Simula√ß√£o de dados de entrada\n",
        "input_data = {\n",
        "    \"temperatura\": [22.5, 23.0, 24.1, 25.3],\n",
        "    \"umidade\": [60, 58, 55, 53]\n",
        "}\n",
        "\n",
        "# Carregando o modelo Cygnus\n",
        "model = AdvancedModel.load(\"cygnus-ultimate\")\n",
        "\n",
        "# Configurando par√¢metros avan√ßados\n",
        "model.configure(precision=\"float16\", optimization_level=3)\n",
        "\n",
        "# Executando tarefa preditiva\n",
        "result = model.execute_task(\"an√°lise preditiva\", data=input_data)\n",
        "print(\"Resultado da an√°lise preditiva:\", result)"
      ],
      "metadata": {
        "id": "FHrJ6baAaGOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä 3. Visualiza√ß√£o com Matplotlib e Seaborn"
      ],
      "metadata": {
        "id": "NNXtaR7kaKGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Convertendo dados simulados em DataFrame\n",
        "df = pd.DataFrame(input_data)\n",
        "\n",
        "# Gr√°fico de linha\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.lineplot(data=df)\n",
        "plt.title(\"S√©ries Temporais - Temperatura e Umidade\")\n",
        "plt.xlabel(\"Tempo\")\n",
        "plt.ylabel(\"Valor\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hYFTfXJ2aK3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üåê 4. Integra√ß√£o com API Externa (Exemplo com OpenWeather)"
      ],
      "metadata": {
        "id": "OshhCaZJaaL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Exemplo de chamada √† API do OpenWeather (substitua pela sua chave)\n",
        "api_key = \"SUA_CHAVE_AQUI\"\n",
        "cidade = \"Salinas,BR\"\n",
        "url = f\"http://api.openweathermap.org/data/2.5/weather?q={cidade}&appid={api_key}&units=metric\"\n",
        "\n",
        "response = requests.get(url)\n",
        "dados = response.json()\n",
        "\n",
        "# Exibindo dados relevantes\n",
        "print(\"Temperatura atual:\", dados[\"main\"][\"temp\"], \"¬∞C\")\n",
        "print(\"Condi√ß√µes clim√°ticas:\", dados[\"weather\"][0][\"description\"])"
      ],
      "metadata": {
        "id": "EWSO24TVabYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß™ Testando a API com Python"
      ],
      "metadata": {
        "id": "J2wf-op6kcj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_KEY = \"sua_chave_aqui\"\n",
        "url = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent\"\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
        "}\n",
        "\n",
        "data = {\n",
        "    \"contents\": [{\"parts\": [{\"text\": \"Explique o impacto da IA multimodal na educa√ß√£o inclusiva.\"}]}]\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, json=data)\n",
        "print(response.json())"
      ],
      "metadata": {
        "id": "6WL2j-xbkezP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìë √çndice do Projeto Hidra\n",
        "\n",
        "- [1. Capa e Identifica√ß√£o](#1-capa-e-identifica√ß√£o)\n",
        "- [2. Objetivo do Projeto](#2-objetivo-do-projeto)\n",
        "- [3. Instala√ß√£o de Bibliotecas](#3-instala√ß√£o-de-bibliotecas)\n",
        "- [4. Granite Instruct ‚Äì Gera√ß√£o de Texto](#4-granite-instruct--gera√ß√£o-de-texto)\n",
        "- [5. Granite Guardian ‚Äì Auditoria √âtica](#5-granite-guardian--auditoria-√©tica)\n",
        "- [6. Granite Vision ‚Äì Classifica√ß√£o de Imagem](#6-granite-vision--classifica√ß√£o-de-imagem)\n",
        "- [7. Whisper ‚Äì Transcri√ß√£o de √Åudio](#7-whisper--transcri√ß√£o-de-√°udio)\n",
        "- [8. FER+ ‚Äì Emo√ß√µes Faciais](#8-fer--emo√ß√µes-faciais)\n",
        "- [9. Operator ‚Äì Racioc√≠nio L√≥gico](#9-operator--racioc√≠nio-l√≥gico)\n",
        "- [10. Interface Interativa](#10-interface-interativa)\n",
        "- [11. Upload de Arquivos](#11-upload-de-arquivos)\n",
        "- [12. Conclus√£o](#12-conclus√£o)\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Capa e Identifica√ß√£o\n",
        "\n",
        "**Discente:** Luiz Augusto Mendes Barbosa  \n",
        "**Institui√ß√£o:** Instituto Federal do Norte de Minas Gerais ‚Äì Campus Salinas  \n",
        "**Curso:** Bacharelado em Sistemas de Informa√ß√£o\n",
        "**Data:** Julho de 2025\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Objetivo do Projeto\n",
        "\n",
        "Desenvolver um sistema de intelig√™ncia artificial multimodal baseado nos modelos IBM Granite, com foco em aplica√ß√µes educacionais, institucionais e √©ticas.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Instala√ß√£o de Bibliotecas\n",
        "\n",
        "```python\n",
        "!pip install transformers fer streamlit whisper openai pillow opencv-python"
      ],
      "metadata": {
        "id": "J84pQ-J5TI7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"IBM/granite-3b-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "prompt = \"Explique os riscos √©ticos do uso de IA em ambientes escolares.\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = model.generate(**inputs, max_new_tokens=250)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "bMKwzEPCUsSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Criar diret√≥rio chamado 'Streamlit'\n",
        "os.makedirs(\"Streamlit\", exist_ok=True)\n",
        "\n",
        "print(\"Diret√≥rio 'Streamlit' criado com sucesso.\")"
      ],
      "metadata": {
        "id": "erJSVJoOU5eA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104303d1-ff6c-4f01-f09a-9283d767b7d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diret√≥rio 'Streamlit' criado com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìù Criar app.py no diret√≥rio Streamlit\n",
        "# Conte√∫do do app Streamlit\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J6wwksD0qaUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conte√∫do do app Streamlit\n",
        "codigo_app = \"\"\"\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"üß† Sistema Hidra ‚Äì Painel Multimodal\")\n",
        "\n",
        "st.header(\"üéß Transcri√ß√£o de √Åudio (Whisper)\")\n",
        "transcricao = st.text_area(\"Resultado da transcri√ß√£o:\", \"Transcri√ß√£o de √°udio: ...\")\n",
        "\n",
        "st.header(\"üòä Emo√ß√µes Detectadas (FER+)\")\n",
        "emocao = st.text_input(\"Emo√ß√£o detectada:\", \"Emo√ß√£o detectada: ...\")\n",
        "\n",
        "st.header(\"üìù Gera√ß√£o de Texto (Hidra Instruct)\")\n",
        "texto = st.text_area(\"Texto gerado:\", \"Texto gerado: ...\")\n",
        "\n",
        "st.header(\"üìà An√°lise Preditiva (Cygnus)\")\n",
        "previsao = st.text_input(\"Previs√£o Cygnus:\", \"An√°lise preditiva: ...\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"‚úÖ Sistema Hidra ‚Äì Interface interativa para visualiza√ß√£o de resultados multimodais.\")\n",
        "\"\"\"\n",
        "\n",
        "# Criar diret√≥rio se n√£o existir\n",
        "import os\n",
        "os.makedirs(\"Streamlit\", exist_ok=True)\n",
        "\n",
        "# Salvar como app.py\n",
        "with open(\"Streamlit/app.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(codigo_app)\n",
        "\n",
        "print(\"Arquivo 'app.py' criado com sucesso em Streamlit/\")"
      ],
      "metadata": {
        "id": "z7at7rQfqCdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codigo_app = \"\"\" import streamlit as st\n",
        "\n",
        "# T√≠tulo do app\n",
        "st.title(\"üß† Sistema Hidra ‚Äì Painel Multimodal\")\n",
        "\n",
        "# Se√ß√µes principais\n",
        "st.header(\"üéß Transcri√ß√£o de √Åudio (Whisper)\")\n",
        "transcricao = st.text_area(\"Resultado da transcri√ß√£o:\", \"Transcri√ß√£o de √°udio: ...\")\n",
        "\n",
        "st.header(\"üòä Emo√ß√µes Detectadas (FER+)\")\n",
        "emocao = st.text_input(\"Emo√ß√£o detectada:\", \"Emo√ß√£o detectada: ...\")\n",
        "\n",
        "st.header(\"üìù Gera√ß√£o de Texto (Hidra Instruct)\")\n",
        "texto = st.text_area(\"Texto gerado:\", \"Texto gerado: ...\")\n",
        "\n",
        "st.header(\"üìà An√°lise Preditiva (Cygnus)\")\n",
        "previsao = st.text_input(\"Previs√£o Cygnus:\", \"An√°lise preditiva: ...\")\n",
        "\n",
        "# Rodap√©\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"‚úÖ Sistema Hidra ‚Äì Interface interativa para visualiza√ß√£o de resultados multimodais.\") \"\"\""
      ],
      "metadata": {
        "id": "hRLdt-lcpUvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codigo_app = \"\"\" import streamlit as st\n",
        "\n",
        "# T√≠tulo do app\n",
        "st.title(\"üß† Sistema Hidra ‚Äì Painel Multimodal\")\n",
        "\n",
        "# Se√ß√µes principais\n",
        "st.header(\"üéß Transcri√ß√£o de √Åudio (Whisper)\")\n",
        "transcricao = st.text_area(\"Resultado da transcri√ß√£o:\", \"Transcri√ß√£o de √°udio: ...\")\n",
        "\n",
        "st.header(\"üòä Emo√ß√µes Detectadas (FER+)\")\n",
        "emocao = st.text_input(\"Emo√ß√£o detectada:\", \"Emo√ß√£o detectada: ...\")\n",
        "\n",
        "st.header(\"üìù Gera√ß√£o de Texto (Hidra Instruct)\")\n",
        "texto = st.text_area(\"Texto gerado:\", \"Texto gerado: ...\")\n",
        "\n",
        "st.header(\"üìà An√°lise Preditiva (Cygnus)\")\n",
        "previsao = st.text_input(\"Previs√£o Cygnus:\", \"An√°lise preditiva: ...\")\n",
        "\n",
        "# Rodap√©\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"‚úÖ Sistema Hidra ‚Äì Interface interativa para visualiza√ß√£o de resultados multimodais.\") \"\"\"\n",
        "\n",
        "with open(\"Streamlit/app.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(codigo_app)"
      ],
      "metadata": {
        "id": "nn0KTIJ1rnnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEsqEZU-tMiw",
        "outputId": "71f099c4-f812-40e5-c19d-8320ddc3b669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.47.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading pyngrok-7.2.12-py3-none-any.whl (26 kB)\n",
            "Downloading streamlit-1.47.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.12 streamlit-1.47.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Abrir t√∫nel na porta 8501 (padr√£o do Streamlit)\n",
        "public_url = ngrok.connect(port=8501)\n",
        "print(\"üîó URL p√∫blica do Streamlit:\", public_url)\n",
        "\n",
        "# Rodar o app Streamlit\n",
        "!streamlit run Streamlit/app.py &"
      ],
      "metadata": {
        "id": "KIjucWBptVdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° Listar os arquivos e diret√≥rios:\n"
      ],
      "metadata": {
        "id": "BtlpW7MVq30q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "metadata": {
        "id": "MzPct484rBA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ver conte√∫do"
      ],
      "metadata": {
        "id": "tdDC0NPKrGF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"Streamlit\")"
      ],
      "metadata": {
        "id": "h7kxgx_6rH_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8ecb15f"
      },
      "source": [
        "!streamlit run Streamlit/app.py &>/dev/null&"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbformat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9ZQVCqTwMFO",
        "outputId": "4e0502a1-3a2e-45b0-fcb9-ba5bbb29a05e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (5.10.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat) (4.25.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat) (5.8.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.11/dist-packages (from nbformat) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat) (0.26.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.8)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nbformat import v4 as nbf\n",
        "import nbformat\n",
        "\n",
        "def criar_notebook(nome=\"Relatorio_Hidra\"):\n",
        "    notebook = nbf.new_notebook()\n",
        "\n",
        "    # C√©lula de introdu√ß√£o\n",
        "    intro = nbf.new_markdown_cell(\"# üß† Relat√≥rio do Sistema Hidra\\nEste notebook documenta os principais m√≥dulos e funcionalidades da IA multimodal Hidra.\")\n",
        "\n",
        "    # C√©lula de importa√ß√µes\n",
        "    imports = nbf.new_code_cell(\"\"\"import matplotlib.pyplot as plt\\nimport seaborn as sns\\nimport pandas as pd\"\"\")\n",
        "\n",
        "    # C√©lula de exemplo de transcri√ß√£o\n",
        "    whisper = nbf.new_code_cell(\"\"\"# üîä M√≥dulo Whisper\\nprint(\"Transcri√ß√£o de √°udio: O aluno demonstrou interesse no tema.\")\"\"\")\n",
        "\n",
        "    # C√©lula de exemplo de emo√ß√£o\n",
        "    fer = nbf.new_code_cell(\"\"\"# üòä M√≥dulo FER+\\nprint(\"Emo√ß√£o detectada: Felicidade\")\"\"\")\n",
        "\n",
        "    # C√©lula de gera√ß√£o de texto\n",
        "    instruct = nbf.new_code_cell(\"\"\"# üìù M√≥dulo Hidra Instruct\\nprint(\"Texto gerado: A IA deve ser usada com responsabilidade em ambientes escolares.\")\"\"\")\n",
        "\n",
        "    # C√©lula de an√°lise preditiva\n",
        "    cygnus = nbf.new_code_cell(\"\"\"# üìà M√≥dulo Cygnus\\nprint(\"Previs√£o de temperatura: 26.3 ¬∞C\")\"\"\")\n",
        "\n",
        "    # Adiciona todas as c√©lulas\n",
        "    notebook.cells = [intro, imports, whisper, fer, instruct, cygnus]\n",
        "\n",
        "    # Salva o notebook\n",
        "    with open(f\"{nome}.ipynb\", \"w\", encoding=\"utf-8\") as f:\n",
        "        nbformat.write(notebook, f)\n",
        "\n",
        "    print(f\"‚úÖ Notebook '{nome}.ipynb' criado com sucesso!\")\n",
        "\n",
        "# Executar a fun√ß√£o\n",
        "criar_notebook()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "xI6-CKD8wlCz",
        "outputId": "420ce02a-0c1c-4426-e147-52f7dd5e0c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'nbformat.v4' has no attribute 'write'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-982491195.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Executar a fun√ß√£o\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mcriar_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-982491195.py\u001b[0m in \u001b[0;36mcriar_notebook\u001b[0;34m(nome)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Salva o notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{nome}.ipynb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mnbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚úÖ Notebook '{nome}.ipynb' criado com sucesso!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'nbformat.v4' has no attribute 'write'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7704cd8",
        "outputId": "d5073399-620e-4e28-f5e4-d909efe6a58d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relatorio_Hidra.ipynb  sample_data  Streamlit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"Relatorio_Hidra.ipynb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lCXbi2OJwrM6",
        "outputId": "e0cb2731-9da9-4576-93fa-ffb7b46c8af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c9015f5e-8821-4b03-8789-d826d6224567\", \"Relatorio_Hidra.ipynb\", 0)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Fzd9xVtTJvLT"
      }
    }
  ]
}