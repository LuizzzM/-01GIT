{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRgtIzUD9mRC0N0gVqz7MR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuizzzM/-01GIT/blob/main/hidra_multimodal_testbed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üåô Hidra Gemini Cygnus Testbed\n",
        "\n",
        "Este notebook apresenta o ambiente de testes do sistema **Hidra**, uma arquitetura de intelig√™ncia artificial multimodal desenvolvida no IFNMG ‚Äì Campus Salinas. A vers√£o atual integra modelos avan√ßados como **Gemini Cygnus**, **Meta-Llama Instruct**, **Whisper**, **FER+**, e m√≥dulos visuais e interativos via **Streamlit**.\n",
        "\n",
        "**Discente:** Luiz Augusto Mendes Barbosa\n",
        "**Institui√ß√£o:** Instituto Federal do Norte de Minas Gerais ‚Äì Campus Salinas\n",
        "**Curso:** Bacharelado em Sistemas de Informa√ß√£o\n",
        "**Data:** Agosto de 2025\n",
        "\n",
        "---\n",
        "## üéØ Objetivo do Projeto\n",
        "\n",
        "Desenvolver um sistema de intelig√™ncia artificial multimodal com foco em aplica√ß√µes educacionais, institucionais e √©ticas, utilizando uma arquitetura modular e transparente para facilitar a pesquisa e a experimenta√ß√£o.\n",
        "**negrito**\n",
        "## üß∞ Componentes Principais\n",
        "- **HidraText**: Gera√ß√£o de texto explicativo com Meta-Llama\n",
        "- **HidraVision**: Classifica√ß√£o e processamento de imagens\n",
        "- **Whisper**: Transcri√ß√£o e an√°lise de voz\n",
        "- **FER+**: Reconhecimento de emo√ß√µes faciais\n",
        "- **Cygnus**: An√°lise preditiva com otimiza√ß√£o avan√ßada\n",
        "\n",
        "---\n",
        "\n",
        "> üí° Este notebook √© um _testbed_ modular e escal√°vel, ideal para experimenta√ß√µes acad√™micas e institucionais com IA √©tica e acess√≠vel."
      ],
      "metadata": {
        "id": "CKsPIzwXiHys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sistema Hidra ‚Äì IA Multimodal com Modelos Hidra\n",
        "\n",
        "Introdu√ß√£o\n",
        "\n",
        "O projeto Hidra √© uma iniciativa acad√™mica desenvolvida no Instituto Federal do Norte de Minas Gerais, com o objetivo de criar um sistema de intelig√™ncia artificial multimodal robusto e √©tico. Este sistema √© baseado na arquitetura Hidra de Luiz Augusto Mendes Barbosa.\n",
        "Conhecida por sua modularidade, transpar√™ncia e compatibilidade com execu√ß√£o local.\n",
        "\n",
        "Refer√™ncias T√©cnicas\n",
        "\n",
        "Modelos Granite: A base do sistema Hidra, incluindo Hidra Vision, Hidra Instruct e Hidra Guardian, que oferecem suporte a tarefas como classifica√ß√£o de imagens, gera√ß√£o de texto e auditoria √©tica.\n",
        "\n",
        "Hugging Face Transformers: Biblioteca amplamente utilizada para implementar modelos de aprendizado profundo em tarefas de NLP, vis√£o computacional e multimodalidade.\n",
        "\n",
        "Whisper: Modelo de transcri√ß√£o de √°udio desenvolvido pela OpenAI, integrado ao Hidra para an√°lise de voz.\n",
        "\n",
        "FER+: Ferramenta para reconhecimento de emo√ß√µes faciais, utilizada para infer√™ncia emocional.\n",
        "\n",
        "Streamlit e Widgets: Tecnologias para criar interfaces interativas e pain√©is de visualiza√ß√£o.\n",
        "\n",
        "O sistema Hidra √© projetado para aplica√ß√µes educacionais, institucionais e √©ticas, com foco em acessibilidade, explicabilidade e responsabilidade.\n"
      ],
      "metadata": {
        "id": "ifSkkHaeRUND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este bloco de c√≥digo instala as bibliotecas necess√°rias para o funcionamento do sistema Hidra.\n",
        "\n",
        "Transformers: Biblioteca essencial para carregar e utilizar modelos pr√©-treinados, como os da fam√≠lia Hidra.\n",
        "\n",
        ".\n",
        "\n",
        "FER: Ferramenta para reconhecimento de emo√ß√µes faciais, integrada ao m√≥dulo de infer√™ncia emocional.\n",
        "\n",
        "Streamlit: Utilizada para criar interfaces interativas e pain√©is de visualiza√ß√£o.\n",
        "\n",
        "Whisper: Modelo de transcri√ß√£o de √°udio, crucial para o m√≥dulo de an√°lise de voz.\n",
        "\n",
        "OpenAI: Biblioteca para integra√ß√£o com modelos avan√ßados de IA.\n",
        "\n",
        "Pillow e OpenCV: Ferramentas para manipula√ß√£o e processamento de imagens, utilizadas no m√≥dulo Hidra Vision.\n",
        "\n",
        "Certifique-se de executar este comando em um ambiente Python com acesso √† internet para garantir a instala√ß√£o bem-sucedida."
      ],
      "metadata": {
        "id": "5xT9Utb3Rlpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers fer streamlit whisper openai pillow opencv-python matplotlib seaborn requests pyngrok ipywidgets"
      ],
      "metadata": {
        "id": "4b6YnAyQTyS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CGL3yT1ZJqno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìù HidraText ‚Äì Gera√ß√£o de Texto Explicativo\n",
        "\n",
        "O modelo Meta-Llama Instruct √© um LLM (Large Language Model) projetado para tarefas de gera√ß√£o de texto e racioc√≠nio. Desenvolvido pela Meta, ele √© otimizado para fornecer respostas explicativas e detalhadas, com foco em √©tica e aplicabilidade pr√°tica. O modelo utiliza um prompt para gerar texto baseado em aprendizado profundo.\n",
        "\n",
        "**Aplica√ß√£o no Hidra:** Este m√≥dulo √© utilizado para criar explica√ß√µes detalhadas e relat√≥rios t√©cnicos, como auditorias √©ticas e an√°lises de impacto."
      ],
      "metadata": {
        "id": "YG1rTenwSMAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "prompt = \"Explique os riscos √©ticos do uso de IA em ambientes escolares.\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = model.generate(**inputs, max_new_tokens=250)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "LIK_Ok7BSP3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° Certifique-se de que o ambiente Python tenha acesso √† internet para baixar os pesos do modelo."
      ],
      "metadata": {
        "id": "y4AUt8UKj00r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üõ°Ô∏è Hidra Guardian ‚Äì Auditoria √âtica Automatizada\n",
        "Este m√≥dulo realiza uma verifica√ß√£o simples e eficaz de riscos √©ticos em textos gerados ou recebidos pelo sistema.\n",
        "\n",
        "‚öôÔ∏è Como Funciona\n",
        "- Analisa o conte√∫do textual em busca de termos sens√≠veis como:\n",
        "- \"emo√ß√£o\"\n",
        "- \"consentimento\"\n",
        "- Se encontrar esses termos, sinaliza um poss√≠vel risco √©tico\n",
        "- Recomenda supervis√£o humana para decis√µes cr√≠ticas\n",
        "\n",
        "üß™ Exemplo de C√≥digo\n"
      ],
      "metadata": {
        "id": "Fnj-McK-SR-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simular_auditoria(prompt_texto):\n",
        "    if \"emo√ß√£o\" in prompt_texto.lower() or \"consentimento\" in prompt_texto.lower():\n",
        "        print(\"‚ö†Ô∏è Risco √©tico detectado: Recomenda-se supervis√£o humana.\")\n",
        "    else:\n",
        "        print(\"‚úÖ Entrada validada: sem risco identificado.\")\n",
        "\n",
        "simular_auditoria(\"A IA pode monitorar emo√ß√µes sem consentimento?\")"
      ],
      "metadata": {
        "id": "pgJYtxTsSVN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Aplica√ß√£o no Sistema Hidra\n",
        "- Pode ser integrado a qualquer m√≥dulo que gere ou analise texto\n",
        "- Funciona como uma camada de seguran√ßa √©tica\n",
        "- Ideal para ambientes educacionais e institucionais que exigem responsabilidade no uso de IA\n"
      ],
      "metadata": {
        "id": "nEcUjhpDk289"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üñºÔ∏è Granite Vision ‚Äì Classifica√ß√£o de Imagem\n",
        "Este m√≥dulo utiliza o modelo Granite Vision da IBM para identificar o conte√∫do de imagens por meio de aprendizado profundo.\n",
        "\n",
        "‚öôÔ∏è Como Funciona\n",
        "- Carrega uma imagem da internet\n",
        "- Processa a imagem com um modelo pr√©-treinado\n",
        "- Retorna a classe prevista com base nos dados visuais\n",
        "\n",
        "üß™ Exemplo de C√≥digo\n"
      ],
      "metadata": {
        "id": "LZa0eyYLSZ8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor, AutoModelForImageClassification\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "model_id = \"IBM/granite-vision-3.2-2b\"\n",
        "image = Image.open(requests.get(\"https://images.unsplash.com/photo-1607746882042-944635dfe10e\", stream=True).raw)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "model = AutoModelForImageClassification.from_pretrained(model_id)\n",
        "\n",
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "print(\"üñºÔ∏è Classe prevista:\", outputs.logits.argmax().item())"
      ],
      "metadata": {
        "id": "O2n_W2THSf8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéôÔ∏è Whisper ‚Äì Transcri√ß√£o de √Åudio e An√°lise de Voz\n",
        "\n",
        "O modelo Whisper, desenvolvido pela OpenAI, √© uma ferramenta avan√ßada para transformar fala em texto com alta precis√£o.\n",
        "üß† Caracter√≠sticas\n",
        "- Suporte a m√∫ltiplos idiomas\n",
        "- Funciona bem mesmo em √°udios com ru√≠do\n",
        "- Gera transcri√ß√µes com pontua√ß√£o e formata√ß√£o b√°sica\n",
        "\n",
        "üß© Aplica√ß√£o no Sistema Hidra\n",
        "- Cria√ß√£o de transcri√ß√µes autom√°ticas\n",
        "- An√°lise de entrada auditiva para complementar vis√£o e emo√ß√£o\n",
        "- Ideal para acessibilidade e inclus√£o educacional\n",
        "\n",
        "üß™ Exemplo de C√≥digo\n"
      ],
      "metadata": {
        "id": "98-CvMyBSjGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "modelo = whisper.load_model(\"base\")\n",
        "resultado = modelo.transcribe(\"caminho_para_audio.wav\")\n",
        "print(\"üó£Ô∏è Transcri√ß√£o:\", resultado[\"text\"])"
      ],
      "metadata": {
        "id": "eoytgYBcSlWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FER+ ‚Äì Infer√™ncia Emocional Baseada em Imagens\n",
        "\n",
        "O m√≥dulo FER+ (Facial Emotion Recognition Plus) permite identificar express√µes faciais e classific√°-las em categorias emocionais, como felicidade, tristeza, surpresa e raiva.\n",
        "\n",
        "Funcionalidades\n",
        "\n",
        "Detectar emo√ß√µes em imagens est√°ticas ou v√≠deo.\n",
        "\n",
        "Usar landmarks faciais e classificadores treinados.\n",
        "\n",
        "Suporte a integra√ß√£o com vis√£o computacional e interfaces interativas.\n",
        "\n",
        "Benef√≠cios Institucionais\n",
        "\n",
        "Possibilita estudos sobre empatia computacional.\n",
        "\n",
        "Apoia aplica√ß√µes educacionais inclusivas e centradas no usu√°rio.\n",
        "\n",
        "Pode ser combinado com an√°lise de voz para infer√™ncia multimodal.\n",
        "\n",
        "Observa√ß√£o\n",
        "\n",
        "O modelo FER+ √© acessado via a biblioteca fer, que utiliza algoritmos baseados em aprendizado profundo para infer√™ncia facial."
      ],
      "metadata": {
        "id": "TAzctHY8Spuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fer import FER\n",
        "import cv2\n",
        "\n",
        "imagem = cv2.imread(\"expressao_usuario.jpg\")\n",
        "detector = FER(mtcnn=True)\n",
        "emocao = detector.detect_emotions(imagem)\n",
        "print(\"üòä Emo√ß√µes detectadas:\", emocao)"
      ],
      "metadata": {
        "id": "0iG5BCaNSrRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Hidra Operator ‚Äì Racioc√≠nio L√≥gico com Transformers\n",
        "Este m√≥dulo utiliza um modelo especializado em racioc√≠nio l√≥gico para gerar sugest√µes baseadas em texto.\n",
        "\n",
        "‚öôÔ∏è Como Funciona\n",
        "- Recebe uma frase como entrada\n",
        "- Classifica a inten√ß√£o ou l√≥gica por tr√°s do texto\n",
        "- Retorna uma classe que representa a sugest√£o l√≥gica\n",
        "\n",
        "üß™ Exemplo de C√≥digo\n"
      ],
      "metadata": {
        "id": "6ADNI2WTSujP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_id = \"Operator/logic-integration-1b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
        "\n",
        "inputs = tokenizer(\"Analise os dados e gere sugest√µes.\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "print(\"üîç Sugest√£o l√≥gica (classe):\", outputs.logits.argmax().item())"
      ],
      "metadata": {
        "id": "2J4PqqpmSx-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° Ideal para an√°lises institucionais, tomada de decis√£o e simula√ß√µes de racioc√≠nio."
      ],
      "metadata": {
        "id": "JDSEHXEsoT3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß© Interface Interativa com Widgets\n",
        "Este m√≥dulo permite criar interfaces simples e funcionais para entrada de texto no notebook.\n",
        "\n",
        "üß™ Exemplo de C√≥digo\n"
      ],
      "metadata": {
        "id": "PYQ9Pdk3S0P5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "entrada = widgets.Text(value='', placeholder='Digite sua pergunta', description='Pergunta:')\n",
        "display(entrada)"
      ],
      "metadata": {
        "id": "DURgw8nhS3xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìÇ 11. Upload de Arquivos\n"
      ],
      "metadata": {
        "id": "XP_T8rtuouG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "-sAfNL92l_I8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìò 12. Conclus√£o\n",
        "\n",
        "O projeto Hidra representa um avan√ßo significativo na pesquisa e desenvolvimento de sistemas de intelig√™ncia artificial multimodal, com foco em √©tica, acessibilidade e aplicabilidade educacional.\n",
        "üåê Impacto Tecnol√≥gico\n",
        "- Integra modelos de ponta como Granite, Whisper, FER+, e Cygnus, cobrindo linguagem, vis√£o, voz e emo√ß√£o.\n",
        "- Utiliza arquitetura modular e escal√°vel, permitindo testes independentes e integra√ß√£o fluida entre componentes.\n",
        "üß† Inova√ß√£o Acad√™mica\n",
        "- Promove o uso de IA em ambientes escolares e institucionais com responsabilidade e transpar√™ncia.\n",
        "- Estimula o pensamento cr√≠tico sobre o papel da tecnologia na educa√ß√£o e na forma√ß√£o √©tica dos usu√°rios.\n",
        "üõ°Ô∏è Responsabilidade e √âtica\n",
        "- M√≥dulos como Hidra Guardian e Hidra Ethica garantem que o sistema opere com supervis√£o √©tica e respeito √† privacidade.\n",
        "- A infer√™ncia emocional e a transcri√ß√£o de voz s√£o aplicadas com foco em inclus√£o e empatia computacional.\n",
        "üìà Pr√≥ximos Passos\n",
        "- Valida√ß√£o T√©cnica: Testar todos os m√≥dulos com dados reais e cen√°rios simulados.\n",
        "- Documenta√ß√£o Expandida: Criar guias de uso e tutoriais para facilitar a ado√ß√£o por outros pesquisadores.\n",
        "- Interface Final: Desenvolver um painel interativo com Streamlit para demonstra√ß√£o p√∫blica.\n",
        "- Publica√ß√£o Cient√≠fica: Consolidar os resultados em um artigo t√©cnico\n"
      ],
      "metadata": {
        "id": "ti5IqTfeS-H4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers fer streamlit whisper openai pillow opencv-python matplotlib seaborn"
      ],
      "metadata": {
        "id": "4QVr4sddZgQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üõ†Ô∏è Fun√ß√£o para Gerar Notebook Din√¢mico"
      ],
      "metadata": {
        "id": "WV3XTPtWZsty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nbformat import v4 as nbf\n",
        "import nbformat\n",
        "\n",
        "def criar_notebook(nome=\"Relatorio_Hidra\"):\n",
        "    notebook = nbf.new_notebook()\n",
        "\n",
        "    # C√©lula de introdu√ß√£o\n",
        "    intro = nbf.new_markdown_cell(\"# üß† Relat√≥rio do Sistema Hidra\\\\nEste notebook documenta os principais m√≥dulos e funcionalidades da IA multimodal Hidra.\")\n",
        "\n",
        "    # C√©lula de importa√ß√µes\n",
        "    imports = nbf.new_code_cell(\"\"\"\"import matplotlib.pyplot as plt\\\\nimport seaborn as sns\\\\nimport pandas as pd\\\"\"\")\n",
        "\n",
        "    # C√©lula de exemplo de transcri√ß√£o\n",
        "    whisper = nbf.new_code_cell(\"\"\"\"# üîä M√≥dulo Whisper\\\\nprint(\\\"Transcri√ß√£o de √°udio: O aluno demonstrou interesse no tema.\\\")\\\"\"\")\n",
        "\n",
        "    # C√©lula de exemplo de emo√ß√£o\n",
        "    fer = nbf.new_code_cell(\"\"\"\"# üòä M√≥dulo FER+\\\\nprint(\\\"Emo√ß√£o detectada: Felicidade\\\")\\\"\"\")\n",
        "\n",
        "    # C√©lula de gera√ß√£o de texto\n",
        "    instruct = nbf.new_code_cell(\"\"\"\"# üìù M√≥dulo Hidra Instruct\\\\nprint(\\\"Texto gerado: A IA deve ser usada com responsabilidade em ambientes escolares.\\\")\\\"\"\")\n",
        "\n",
        "    # C√©lula de an√°lise preditiva\n",
        "    cygnus = nbf.new_code_cell(\"\"\"\"# üìà M√≥dulo Cygnus\\\\nprint(\\\"Previs√£o de temperatura: 26.3 ¬∞C\\\")\\\"\"\")\n",
        "\n",
        "    # Adiciona todas as c√©lulas\n",
        "    notebook.cells = [intro, imports, whisper, fer, instruct, cygnus]\n",
        "\n",
        "    # Salva o notebook\n",
        "    with open(f\"{nome}.ipynb\", \"w\", encoding=\"utf-8\") as f:\n",
        "        nbformat.write(notebook, f)\n",
        "\n",
        "    print(f\"‚úÖ Notebook '{nome}.ipynb' criado com sucesso!\")\n",
        "\n",
        "# Executar a fun√ß√£o para criar o notebook\n",
        "criar_notebook()"
      ],
      "metadata": {
        "id": "7-bifo3qZupB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† 2. M√≥dulo Cygnus ‚Äì Execu√ß√£o Preditiva"
      ],
      "metadata": {
        "id": "pTPAbjKkaEfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gemini import AdvancedModel\n",
        "\n",
        "# Simula√ß√£o de dados de entrada\n",
        "input_data = {\n",
        "    \"temperatura\": [22.5, 23.0, 24.1, 25.3],\n",
        "    \"umidade\": [60, 58, 55, 53]\n",
        "}\n",
        "\n",
        "# Carregando o modelo Cygnus\n",
        "model = AdvancedModel.load(\"cygnus-ultimate\")\n",
        "\n",
        "# Configurando par√¢metros avan√ßados\n",
        "model.configure(precision=\"float16\", optimization_level=3)\n",
        "\n",
        "# Executando tarefa preditiva\n",
        "result = model.execute_task(\"an√°lise preditiva\", data=input_data)\n",
        "print(\"Resultado da an√°lise preditiva:\", result)"
      ],
      "metadata": {
        "id": "FHrJ6baAaGOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä 3. Visualiza√ß√£o com Matplotlib e Seaborn"
      ],
      "metadata": {
        "id": "NNXtaR7kaKGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Convertendo dados simulados em DataFrame\n",
        "df = pd.DataFrame(input_data)\n",
        "\n",
        "# Gr√°fico de linha\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.lineplot(data=df)\n",
        "plt.title(\"S√©ries Temporais - Temperatura e Umidade\")\n",
        "plt.xlabel(\"Tempo\")\n",
        "plt.ylabel(\"Valor\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hYFTfXJ2aK3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üåê 4. Integra√ß√£o com API Externa (Exemplo com OpenWeather)"
      ],
      "metadata": {
        "id": "OshhCaZJaaL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Exemplo de chamada √† API do OpenWeather (substitua pela sua chave)\n",
        "api_key = \"SUA_CHAVE_AQUI\"\n",
        "cidade = \"Salinas,BR\"\n",
        "url = f\"http://api.openweathermap.org/data/2.5/weather?q={cidade}&appid={api_key}&units=metric\"\n",
        "\n",
        "response = requests.get(url)\n",
        "dados = response.json()\n",
        "\n",
        "# Exibindo dados relevantes\n",
        "print(\"Temperatura atual:\", dados[\"main\"][\"temp\"], \"¬∞C\")\n",
        "print(\"Condi√ß√µes clim√°ticas:\", dados[\"weather\"][0][\"description\"])"
      ],
      "metadata": {
        "id": "EWSO24TVabYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß™ Testando a API com Python"
      ],
      "metadata": {
        "id": "J2wf-op6kcj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_KEY = \"sua_chave_aqui\"\n",
        "url = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent\"\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
        "}\n",
        "\n",
        "data = {\n",
        "    \"contents\": [{\"parts\": [{\"text\": \"Explique o impacto da IA multimodal na educa√ß√£o inclusiva.\"}]}]\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, json=data)\n",
        "print(response.json())"
      ],
      "metadata": {
        "id": "6WL2j-xbkezP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìë √çndice do Projeto Hidra\n",
        "\n",
        "- [1. Capa e Identifica√ß√£o](#1-capa-e-identifica√ß√£o)\n",
        "- [2. Objetivo do Projeto](#2-objetivo-do-projeto)\n",
        "- [3. Instala√ß√£o de Bibliotecas](#3-instala√ß√£o-de-bibliotecas)\n",
        "- [4. HidraText ‚Äì Gera√ß√£o de Texto](#4-hidratext--gera√ß√£o-de-texto)\n",
        "- [5. Hidra Guardian ‚Äì Auditoria √âtica](#5-hidra-guardian--auditoria-√©tica)\n",
        "- [6. Hidra Vision ‚Äì Classifica√ß√£o de Imagem](#6-hidra-vision--classifica√ß√£o-de-imagem)\n",
        "- [7. Whisper ‚Äì Transcri√ß√£o de √Åudio](#7-whisper--transcri√ß√£o-de-√°udio)\n",
        "- [8. FER+ ‚Äì Emo√ß√µes Faciais](#8-fer--emo√ß√µes-faciais)\n",
        "- [9. Operator ‚Äì Racioc√≠nio L√≥gico](#9-operator--racioc√≠nio-l√≥gico)\n",
        "- [10. Interface Interativa](#10-interface-interativa)\n",
        "- [11. Upload de Arquivos](#11-upload-de-arquivos)\n",
        "- [12. Conclus√£o](#12-conclus√£o)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "J84pQ-J5TI7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"IBM/granite-3b-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "prompt = \"Explique os riscos √©ticos do uso de IA em ambientes escolares.\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = model.generate(**inputs, max_new_tokens=250)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "bMKwzEPCUsSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Criar diret√≥rio chamado 'Streamlit'\n",
        "os.makedirs(\"Streamlit\", exist_ok=True)\n",
        "\n",
        "print(\"Diret√≥rio 'Streamlit' criado com sucesso.\")"
      ],
      "metadata": {
        "id": "erJSVJoOU5eA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104303d1-ff6c-4f01-f09a-9283d767b7d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diret√≥rio 'Streamlit' criado com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìù Criar app.py no diret√≥rio Streamlit\n",
        "# Conte√∫do do app Streamlit\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J6wwksD0qaUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conte√∫do do app Streamlit\n",
        "codigo_app = \"\"\"\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"üß† Sistema Hidra ‚Äì Painel Multimodal\")\n",
        "\n",
        "st.header(\"üéß Transcri√ß√£o de √Åudio (Whisper)\")\n",
        "transcricao = st.text_area(\"Resultado da transcri√ß√£o:\", \"Transcri√ß√£o de √°udio: ...\")\n",
        "\n",
        "st.header(\"üòä Emo√ß√µes Detectadas (FER+)\")\n",
        "emocao = st.text_input(\"Emo√ß√£o detectada:\", \"Emo√ß√£o detectada: ...\")\n",
        "\n",
        "st.header(\"üìù Gera√ß√£o de Texto (Hidra Instruct)\")\n",
        "texto = st.text_area(\"Texto gerado:\", \"Texto gerado: ...\")\n",
        "\n",
        "st.header(\"üìà An√°lise Preditiva (Cygnus)\")\n",
        "previsao = st.text_input(\"Previs√£o Cygnus:\", \"An√°lise preditiva: ...\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"‚úÖ Sistema Hidra ‚Äì Interface interativa para visualiza√ß√£o de resultados multimodais.\")\n",
        "\"\"\"\n",
        "\n",
        "# Criar diret√≥rio se n√£o existir e salvar o arquivo\n",
        "import os\n",
        "os.makedirs(\"Streamlit\", exist_ok=True)\n",
        "\n",
        "with open(\"Streamlit/app.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(codigo_app)\n",
        "\n",
        "print(\"Arquivo 'app.py' criado com sucesso em Streamlit/\")"
      ],
      "metadata": {
        "id": "z7at7rQfqCdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codigo_app = \"\"\" import streamlit as st\n",
        "\n",
        "# T√≠tulo do app\n",
        "st.title(\"üß† Sistema Hidra ‚Äì Painel Multimodal\")\n",
        "\n",
        "# Se√ß√µes principais\n",
        "st.header(\"üéß Transcri√ß√£o de √Åudio (Whisper)\")\n",
        "transcricao = st.text_area(\"Resultado da transcri√ß√£o:\", \"Transcri√ß√£o de √°udio: ...\")\n",
        "\n",
        "st.header(\"üòä Emo√ß√µes Detectadas (FER+)\")\n",
        "emocao = st.text_input(\"Emo√ß√£o detectada:\", \"Emo√ß√£o detectada: ...\")\n",
        "\n",
        "st.header(\"üìù Gera√ß√£o de Texto (Hidra Instruct)\")\n",
        "texto = st.text_area(\"Texto gerado:\", \"Texto gerado: ...\")\n",
        "\n",
        "st.header(\"üìà An√°lise Preditiva (Cygnus)\")\n",
        "previsao = st.text_input(\"Previs√£o Cygnus:\", \"An√°lise preditiva: ...\")\n",
        "\n",
        "# Rodap√©\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"‚úÖ Sistema Hidra ‚Äì Interface interativa para visualiza√ß√£o de resultados multimodais.\") \"\"\""
      ],
      "metadata": {
        "id": "hRLdt-lcpUvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codigo_app = \"\"\" import streamlit as st\n",
        "\n",
        "# T√≠tulo do app\n",
        "st.title(\"üß† Sistema Hidra ‚Äì Painel Multimodal\")\n",
        "\n",
        "# Se√ß√µes principais\n",
        "st.header(\"üéß Transcri√ß√£o de √Åudio (Whisper)\")\n",
        "transcricao = st.text_area(\"Resultado da transcri√ß√£o:\", \"Transcri√ß√£o de √°udio: ...\")\n",
        "\n",
        "st.header(\"üòä Emo√ß√µes Detectadas (FER+)\")\n",
        "emocao = st.text_input(\"Emo√ß√£o detectada:\", \"Emo√ß√£o detectada: ...\")\n",
        "\n",
        "st.header(\"üìù Gera√ß√£o de Texto (Hidra Instruct)\")\n",
        "texto = st.text_area(\"Texto gerado:\", \"Texto gerado: ...\")\n",
        "\n",
        "st.header(\"üìà An√°lise Preditiva (Cygnus)\")\n",
        "previsao = st.text_input(\"Previs√£o Cygnus:\", \"An√°lise preditiva: ...\")\n",
        "\n",
        "# Rodap√©\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"‚úÖ Sistema Hidra ‚Äì Interface interativa para visualiza√ß√£o de resultados multimodais.\") \"\"\"\n",
        "\n",
        "with open(\"Streamlit/app.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(codigo_app)"
      ],
      "metadata": {
        "id": "nn0KTIJ1rnnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° Listar os arquivos e diret√≥rios:\n"
      ],
      "metadata": {
        "id": "BtlpW7MVq30q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "metadata": {
        "id": "MzPct484rBA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ver conte√∫do"
      ],
      "metadata": {
        "id": "tdDC0NPKrGF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"Streamlit\")"
      ],
      "metadata": {
        "id": "h7kxgx_6rH_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8ecb15f"
      },
      "source": [
        "!streamlit run Streamlit/app.py &>/dev/null&"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Abrir t√∫nel na porta 8501 (padr√£o do Streamlit)\n",
        "public_url = ngrok.connect(port=8501)\n",
        "print(\"üîó URL p√∫blica do Streamlit:\", public_url)\n",
        "\n",
        "# Rodar o app Streamlit\n",
        "!streamlit run Streamlit/app.py &"
      ],
      "metadata": {
        "id": "KIjucWBptVdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nbformat import v4 as nbf\n",
        "import nbformat\n",
        "\n",
        "def criar_notebook(nome=\"Relatorio_Hidra\"):\n",
        "    notebook = nbf.new_notebook()\n",
        "\n",
        "    # C√©lula de introdu√ß√£o\n",
        "    intro = nbf.new_markdown_cell(\"# üß† Relat√≥rio do Sistema Hidra\\\\nEste notebook documenta os principais m√≥dulos e funcionalidades da IA multimodal Hidra.\")\n",
        "\n",
        "    # C√©lula de importa√ß√µes\n",
        "    imports = nbf.new_code_cell(\"\"\"\"import matplotlib.pyplot as plt\\\\nimport seaborn as sns\\\\nimport pandas as pd\\\"\"\")\n",
        "\n",
        "    # C√©lula de exemplo de transcri√ß√£o\n",
        "    whisper = nbf.new_code_cell(\"\"\"\"# üîä M√≥dulo Whisper\\\\nprint(\\\"Transcri√ß√£o de √°udio: O aluno demonstrou interesse no tema.\\\")\\\"\"\")\n",
        "\n",
        "    # C√©lula de exemplo de emo√ß√£o\n",
        "    fer = nbf.new_code_cell(\"\"\"\"# üòä M√≥dulo FER+\\\\nprint(\\\"Emo√ß√£o detectada: Felicidade\\\")\\\"\"\")\n",
        "\n",
        "    # C√©lula de gera√ß√£o de texto\n",
        "    instruct = nbf.new_code_cell(\"\"\"\"# üìù M√≥dulo Hidra Instruct\\\\nprint(\\\"Texto gerado: A IA deve ser usada com responsabilidade em ambientes escolares.\\\")\\\"\"\")\n",
        "\n",
        "    # C√©lula de an√°lise preditiva\n",
        "    cygnus = nbf.new_code_cell(\"\"\"\"# üìà M√≥dulo Cygnus\\\\nprint(\\\"Previs√£o de temperatura: 26.3 ¬∞C\\\")\\\"\"\")\n",
        "\n",
        "    # Adiciona todas as c√©lulas\n",
        "    notebook.cells = [intro, imports, whisper, fer, instruct, cygnus]\n",
        "\n",
        "    # Salva o notebook\n",
        "    with open(f\"{nome}.ipynb\", \"w\", encoding=\"utf-8\") as f:\n",
        "        nbformat.write(notebook, f)\n",
        "\n",
        "    print(f\"‚úÖ Notebook '{nome}.ipynb' criado com sucesso!\")\n",
        "\n",
        "# Executar a fun√ß√£o para criar o notebook\n",
        "criar_notebook()"
      ],
      "metadata": {
        "id": "xI6-CKD8wlCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7704cd8",
        "outputId": "d5073399-620e-4e28-f5e4-d909efe6a58d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relatorio_Hidra.ipynb  sample_data  Streamlit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Fzd9xVtTJvLT"
      }
    }
  ]
}