{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPe2QgzGYzieWGbZidULd+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuizzzM/-01GIT/blob/main/hidra_multimodal_testbed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ§  Hidra Gemini Cygnus Testbed\n",
        "\n",
        "Este notebook apresenta o ambiente de testes do sistema **Hidra**, uma arquitetura de inteligÃªncia artificial multimodal desenvolvida no IFNMG â€“ Campus Salinas. A versÃ£o atual integra modelos avanÃ§ados como **Gemini Cygnus**, **Meta-Llama Instruct**, **Whisper**, **FER+**, e mÃ³dulos visuais e interativos via **Streamlit**.\n",
        "\n",
        "## ğŸ¯ Objetivos\n",
        "- Testar e validar a integraÃ§Ã£o de modelos multimodais\n",
        "- Realizar auditorias Ã©ticas e inferÃªncias emocionais\n",
        "- Simular cenÃ¡rios institucionais com entrada de voz, imagem e texto\n",
        "\n",
        "## ğŸ§° Componentes Principais\n",
        "- **HidraText**: GeraÃ§Ã£o de texto explicativo com Meta-Llama\n",
        "- **HidraVision**: ClassificaÃ§Ã£o e processamento de imagens\n",
        "- **Whisper**: TranscriÃ§Ã£o e anÃ¡lise de voz\n",
        "- **FER+**: Reconhecimento de emoÃ§Ãµes faciais\n",
        "- **Cygnus**: AnÃ¡lise preditiva com otimizaÃ§Ã£o avanÃ§ada\n",
        "\n",
        "---\n",
        "\n",
        "> ğŸ’¡ Este notebook Ã© um _testbed_ modular e escalÃ¡vel, ideal para experimentaÃ§Ãµes acadÃªmicas e institucionais com IA Ã©tica e acessÃ­vel."
      ],
      "metadata": {
        "id": "CKsPIzwXiHys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sistema Hidra â€“ IA Multimodal com Modelos Hidra\n",
        "\n",
        "IntroduÃ§Ã£o\n",
        "\n",
        "O projeto Hidra Ã© uma iniciativa acadÃªmica desenvolvida no Instituto Federal do Norte de Minas Gerais, com o objetivo de criar um sistema de inteligÃªncia artificial multimodal robusto e Ã©tico. Este sistema Ã© baseado na arquitetura Hidra de Luiz Augusto Mendes Barbosa.\n",
        "Conhecida por sua modularidade, transparÃªncia e compatibilidade com execuÃ§Ã£o local.\n",
        "\n",
        "ReferÃªncias TÃ©cnicas\n",
        "\n",
        "Modelos Granite: A base do sistema Hidra, incluindo Hidra Vision, Hidra Instruct e Hidra Guardian, que oferecem suporte a tarefas como classificaÃ§Ã£o de imagens, geraÃ§Ã£o de texto e auditoria Ã©tica.\n",
        "\n",
        "Hugging Face Transformers: Biblioteca amplamente utilizada para implementar modelos de aprendizado profundo em tarefas de NLP, visÃ£o computacional e multimodalidade.\n",
        "\n",
        "Whisper: Modelo de transcriÃ§Ã£o de Ã¡udio desenvolvido pela OpenAI, integrado ao Hidra para anÃ¡lise de voz.\n",
        "\n",
        "FER+: Ferramenta para reconhecimento de emoÃ§Ãµes faciais, utilizada para inferÃªncia emocional.\n",
        "\n",
        "Streamlit e Widgets: Tecnologias para criar interfaces interativas e painÃ©is de visualizaÃ§Ã£o.\n",
        "\n",
        "O sistema Hidra Ã© projetado para aplicaÃ§Ãµes educacionais, institucionais e Ã©ticas, com foco em acessibilidade, explicabilidade e responsabilidade.\n"
      ],
      "metadata": {
        "id": "ifSkkHaeRUND"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N7V-quARA5j"
      },
      "outputs": [],
      "source": [
        "# Sistema Hidra â€“ IA\n",
        "**Discente:** Luiz Augusto Mendes Barbosa\n",
        "**InstituiÃ§Ã£o:** Instituto Federal do Norte de Minas Gerais â€“ Campus Salinas\n",
        "**Curso:** Bacharelado em Sistemas De InformaÃ§Ã£o\n",
        "**Data:** Agosto de 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ExplicaÃ§Ã£o TÃ©cnica\n",
        "\n",
        "Este bloco de cÃ³digo instala as bibliotecas necessÃ¡rias para o funcionamento do sistema Hidra.\n",
        "\n",
        "Transformers: Biblioteca essencial para carregar e utilizar modelos prÃ©-treinados, como os da famÃ­lia\n",
        "\n",
        "Hidra\n",
        "\n",
        ".\n",
        "\n",
        "FER: Ferramenta para reconhecimento de emoÃ§Ãµes faciais, integrada ao mÃ³dulo de inferÃªncia emocional.\n",
        "\n",
        "Streamlit: Utilizada para criar interfaces interativas e painÃ©is de visualizaÃ§Ã£o.\n",
        "\n",
        "Whisper: Modelo de transcriÃ§Ã£o de Ã¡udio, crucial para o mÃ³dulo de anÃ¡lise de voz.\n",
        "\n",
        "OpenAI: Biblioteca para integraÃ§Ã£o com modelos avanÃ§ados de IA.\n",
        "\n",
        "Pillow e OpenCV: Ferramentas para manipulaÃ§Ã£o e processamento de imagens, utilizadas no mÃ³dulo Hidra Vision.\n",
        "\n",
        "Certifique-se de executar este comando em um ambiente Python com acesso Ã  internet para garantir a instalaÃ§Ã£o bem-sucedida."
      ],
      "metadata": {
        "id": "5xT9Utb3Rlpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers fer streamlit whisper openai pillow opencv-python"
      ],
      "metadata": {
        "id": "4b6YnAyQTyS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54532634-1ece-4e47-d05c-66d17b2b2c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.1)\n",
            "Collecting fer\n",
            "  Downloading fer-22.5.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.47.1)\n",
            "Collecting whisper\n",
            "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.97.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from fer) (3.10.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from fer) (4.12.0.88)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fer) (3.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from fer) (2.2.2)\n",
            "Collecting facenet-pytorch (from fer)\n",
            "  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (from fer) (1.0.3)\n",
            "Collecting ffmpeg==1.4 (from fer)\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from whisper) (1.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=2.0.0->fer) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=2.0.0->fer) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=2.0.0->fer) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=2.0.0->fer) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=2.0.0->fer) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=2.0.0->fer) (0.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->fer) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->fer) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->fer) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "INFO: pip is looking at multiple versions of facenet-pytorch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting facenet-pytorch (from fer)\n",
            "  Downloading facenet_pytorch-2.5.3-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch->fer) (0.21.0+cu124)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fer) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fer) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fer) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fer) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fer) (3.2.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy->fer) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy->fer) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy->fer) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy->fer) (0.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.0.0->fer) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.0.0->fer) (2.19.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->facenet-pytorch->fer) (2.6.0+cu124)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision->facenet-pytorch->fer) (3.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision->facenet-pytorch->fer) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision->facenet-pytorch->fer) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision->facenet-pytorch->fer) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision->facenet-pytorch->fer)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision->facenet-pytorch->fer) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision->facenet-pytorch->fer) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision->facenet-pytorch->fer) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.0.0->fer) (0.1.2)\n",
            "Downloading fer-22.5.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m762.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ffmpeg, whisper\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=ce97e7cd96b75159016ec8c26bba09dcee25c9274ad0b84625b9ef33c573a31b\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/30/c5/576bdd729f3bc062d62a551be7fefd6ed2f761901568171e4e\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41120 sha256=0cf0d6c74ed1a24c40e694b20e9f3453368f51156d5cf7f22540624b5a2e88e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/65/ee/4e6672aabfa486d3341a39a04f8f87c77e5156149299b5a7d0\n",
            "Successfully built ffmpeg whisper\n",
            "Installing collected packages: ffmpeg, whisper, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, facenet-pytorch, fer\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed facenet-pytorch-2.5.3 fer-22.5.1 ffmpeg-1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 whisper-1.1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CGL3yT1ZJqno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HidraText â€“ GeraÃ§Ã£o de Texto Explicativo\n",
        "\n",
        "ExplicaÃ§Ã£o TÃ©cnica\n",
        "\n",
        "O modelo Meta-Llama Instruct Ã© um LLM (Large Language Model) projetado para tarefas de geraÃ§Ã£o de texto e raciocÃ­nio.\n",
        "\n",
        "HistÃ³ria do Modelo: Desenvolvido pela Meta, o Meta-Llama Instruct Ã© otimizado para fornecer respostas explicativas e detalhadas, com foco em Ã©tica e aplicabilidade prÃ¡tica.\n",
        "\n",
        "Funcionamento: O modelo utiliza um prompt para gerar texto baseado em aprendizado profundo.\n",
        "\n",
        "AplicaÃ§Ã£o no Hidra: Este modelo Ã© utilizado para criar explicaÃ§Ãµes detalhadas e relatÃ³rios tÃ©cnicos, como auditorias Ã©ticas e anÃ¡lises de impacto.\n",
        "\n",
        "O cÃ³digo abaixo demonstra como carregar o modelo, preparar um prompt e gerar uma resposta. Certifique-se de que o ambiente Python tenha acesso Ã  internet para baixar os pesos do modelo."
      ],
      "metadata": {
        "id": "YG1rTenwSMAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "prompt = \"Explique os riscos Ã©ticos do uso de IA em ambientes escolares.\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = model.generate(**inputs, max_new_tokens=250)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "LIK_Ok7BSP3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ’¡ Certifique-se de que o ambiente Python tenha acesso Ã  internet para baixar os pesos do modelo."
      ],
      "metadata": {
        "id": "y4AUt8UKj00r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ›¡ï¸ Hidra Guardian â€“ Auditoria Ã‰tica Automatizada\n",
        "Este mÃ³dulo realiza uma verificaÃ§Ã£o simples e eficaz de riscos Ã©ticos em textos gerados ou recebidos pelo sistema.\n",
        "\n",
        "âš™ï¸ Como Funciona\n",
        "- Analisa o conteÃºdo textual em busca de termos sensÃ­veis como:\n",
        "- \"emoÃ§Ã£o\"\n",
        "- \"consentimento\"\n",
        "- Se encontrar esses termos, sinaliza um possÃ­vel risco Ã©tico\n",
        "- Recomenda supervisÃ£o humana para decisÃµes crÃ­ticas\n",
        "\n",
        "ğŸ§ª Exemplo de CÃ³digo\n"
      ],
      "metadata": {
        "id": "Fnj-McK-SR-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simular_auditoria(prompt_texto):\n",
        "    if \"emoÃ§Ã£o\" in prompt_texto.lower() or \"consentimento\" in prompt_texto.lower():\n",
        "        print(\"âš ï¸ Risco Ã©tico detectado: Recomenda-se supervisÃ£o humana.\")\n",
        "    else:\n",
        "        print(\"âœ… Entrada validada: sem risco identificado.\")\n",
        "\n",
        "simular_auditoria(\"A IA pode monitorar emoÃ§Ãµes sem consentimento?\")"
      ],
      "metadata": {
        "id": "pgJYtxTsSVN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ§  AplicaÃ§Ã£o no Sistema Hidra\n",
        "- Pode ser integrado a qualquer mÃ³dulo que gere ou analise texto\n",
        "- Funciona como uma camada de seguranÃ§a Ã©tica\n",
        "- Ideal para ambientes educacionais e institucionais que exigem responsabilidade no uso de IA\n"
      ],
      "metadata": {
        "id": "nEcUjhpDk289"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ–¼ï¸ Granite Vision â€“ ClassificaÃ§Ã£o de Imagem\n",
        "Este mÃ³dulo utiliza o modelo Granite Vision da IBM para identificar o conteÃºdo de imagens por meio de aprendizado profundo.\n",
        "\n",
        "âš™ï¸ Como Funciona\n",
        "- Carrega uma imagem da internet\n",
        "- Processa a imagem com um modelo prÃ©-treinado\n",
        "- Retorna a classe prevista com base nos dados visuais\n",
        "\n",
        "ğŸ§ª Exemplo de CÃ³digo\n"
      ],
      "metadata": {
        "id": "LZa0eyYLSZ8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor, AutoModelForImageClassification\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "model_id = \"IBM/granite-vision-3.2-2b\"\n",
        "image = Image.open(requests.get(\"https://images.unsplash.com/photo-1607746882042-944635dfe10e\", stream=True).raw)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "model = AutoModelForImageClassification.from_pretrained(model_id)\n",
        "\n",
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "print(\"ğŸ–¼ï¸ Classe prevista:\", outputs.logits.argmax().item())"
      ],
      "metadata": {
        "id": "O2n_W2THSf8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ™ï¸ Whisper â€“ TranscriÃ§Ã£o de Ãudio e AnÃ¡lise de Voz\n",
        "\n",
        "O modelo Whisper, desenvolvido pela OpenAI, Ã© uma ferramenta avanÃ§ada para transformar fala em texto com alta precisÃ£o.\n",
        "ğŸ§  CaracterÃ­sticas\n",
        "- Suporte a mÃºltiplos idiomas\n",
        "- Funciona bem mesmo em Ã¡udios com ruÃ­do\n",
        "- Gera transcriÃ§Ãµes com pontuaÃ§Ã£o e formataÃ§Ã£o bÃ¡sica\n",
        "\n",
        "ğŸ§© AplicaÃ§Ã£o no Sistema Hidra\n",
        "- CriaÃ§Ã£o de transcriÃ§Ãµes automÃ¡ticas\n",
        "- AnÃ¡lise de entrada auditiva para complementar visÃ£o e emoÃ§Ã£o\n",
        "- Ideal para acessibilidade e inclusÃ£o educacional\n",
        "\n",
        "ğŸ§ª Exemplo de CÃ³digo\n"
      ],
      "metadata": {
        "id": "98-CvMyBSjGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "modelo = whisper.load_model(\"base\")\n",
        "resultado = modelo.transcribe(\"caminho_para_audio.wav\")\n",
        "print(\"ğŸ—£ï¸ TranscriÃ§Ã£o:\", resultado[\"text\"])"
      ],
      "metadata": {
        "id": "eoytgYBcSlWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FER+ â€“ InferÃªncia Emocional Baseada em Imagens\n",
        "\n",
        "O mÃ³dulo FER+ (Facial Emotion Recognition Plus) permite identificar expressÃµes faciais e classificÃ¡-las em categorias emocionais, como felicidade, tristeza, surpresa e raiva.\n",
        "\n",
        "Funcionalidades\n",
        "\n",
        "Detectar emoÃ§Ãµes em imagens estÃ¡ticas ou vÃ­deo.\n",
        "\n",
        "Usar landmarks faciais e classificadores treinados.\n",
        "\n",
        "Suporte a integraÃ§Ã£o com visÃ£o computacional e interfaces interativas.\n",
        "\n",
        "BenefÃ­cios Institucionais\n",
        "\n",
        "Possibilita estudos sobre empatia computacional.\n",
        "\n",
        "Apoia aplicaÃ§Ãµes educacionais inclusivas e centradas no usuÃ¡rio.\n",
        "\n",
        "Pode ser combinado com anÃ¡lise de voz para inferÃªncia multimodal.\n",
        "\n",
        "ObservaÃ§Ã£o\n",
        "\n",
        "O modelo FER+ Ã© acessado via a biblioteca fer, que utiliza algoritmos baseados em aprendizado profundo para inferÃªncia facial."
      ],
      "metadata": {
        "id": "TAzctHY8Spuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fer import FER\n",
        "import cv2\n",
        "\n",
        "imagem = cv2.imread(\"expressao_usuario.jpg\")\n",
        "detector = FER(mtcnn=True)\n",
        "emocao = detector.detect_emotions(imagem)\n",
        "print(\"ğŸ˜Š EmoÃ§Ãµes detectadas:\", emocao)"
      ],
      "metadata": {
        "id": "0iG5BCaNSrRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ§  Hidra Operator â€“ RaciocÃ­nio LÃ³gico com Transformers\n",
        "Este mÃ³dulo utiliza um modelo especializado em raciocÃ­nio lÃ³gico para gerar sugestÃµes baseadas em texto.\n",
        "\n",
        "âš™ï¸ Como Funciona\n",
        "- Recebe uma frase como entrada\n",
        "- Classifica a intenÃ§Ã£o ou lÃ³gica por trÃ¡s do texto\n",
        "- Retorna uma classe que representa a sugestÃ£o lÃ³gica\n",
        "\n",
        "ğŸ§ª Exemplo de CÃ³digo\n"
      ],
      "metadata": {
        "id": "6ADNI2WTSujP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_id = \"Operator/logic-integration-1b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
        "\n",
        "inputs = tokenizer(\"Analise os dados e gere sugestÃµes.\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "print(\"ğŸ” SugestÃ£o lÃ³gica (classe):\", outputs.logits.argmax().item())"
      ],
      "metadata": {
        "id": "2J4PqqpmSx-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ’¡ Ideal para anÃ¡lises institucionais, tomada de decisÃ£o e simulaÃ§Ãµes de raciocÃ­nio."
      ],
      "metadata": {
        "id": "JDSEHXEsoT3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ§© Interface Interativa com Widgets\n",
        "Este mÃ³dulo permite criar interfaces simples e funcionais para entrada de texto no notebook.\n",
        "\n",
        "ğŸ§ª Exemplo de CÃ³digo\n"
      ],
      "metadata": {
        "id": "PYQ9Pdk3S0P5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "entrada = widgets.Text(value='', placeholder='Digite sua pergunta', description='Pergunta:')\n",
        "display(entrada)"
      ],
      "metadata": {
        "id": "DURgw8nhS3xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ“‚ 11. Upload de Arquivos\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "XP_T8rtuouG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "-sAfNL92l_I8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ“˜ 12. ConclusÃ£o\n",
        "\n",
        "O projeto Hidra representa um avanÃ§o significativo na pesquisa e desenvolvimento de sistemas de inteligÃªncia artificial multimodal, com foco em Ã©tica, acessibilidade e aplicabilidade educacional.\n",
        "ğŸŒ Impacto TecnolÃ³gico\n",
        "- Integra modelos de ponta como Granite, Whisper, FER+, e Cygnus, cobrindo linguagem, visÃ£o, voz e emoÃ§Ã£o.\n",
        "- Utiliza arquitetura modular e escalÃ¡vel, permitindo testes independentes e integraÃ§Ã£o fluida entre componentes.\n",
        "ğŸ§  InovaÃ§Ã£o AcadÃªmica\n",
        "- Promove o uso de IA em ambientes escolares e institucionais com responsabilidade e transparÃªncia.\n",
        "- Estimula o pensamento crÃ­tico sobre o papel da tecnologia na educaÃ§Ã£o e na formaÃ§Ã£o Ã©tica dos usuÃ¡rios.\n",
        "ğŸ›¡ï¸ Responsabilidade e Ã‰tica\n",
        "- MÃ³dulos como Hidra Guardian e Hidra Ethica garantem que o sistema opere com supervisÃ£o Ã©tica e respeito Ã  privacidade.\n",
        "- A inferÃªncia emocional e a transcriÃ§Ã£o de voz sÃ£o aplicadas com foco em inclusÃ£o e empatia computacional.\n",
        "ğŸ“ˆ PrÃ³ximos Passos\n",
        "- ValidaÃ§Ã£o TÃ©cnica: Testar todos os mÃ³dulos com dados reais e cenÃ¡rios simulados.\n",
        "- DocumentaÃ§Ã£o Expandida: Criar guias de uso e tutoriais para facilitar a adoÃ§Ã£o por outros pesquisadores.\n",
        "- Interface Final: Desenvolver um painel interativo com Streamlit para demonstraÃ§Ã£o pÃºblica.\n",
        "- PublicaÃ§Ã£o CientÃ­fica: Consolidar os resultados em um artigo tÃ©cnico\n"
      ],
      "metadata": {
        "id": "ti5IqTfeS-H4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "2pfD2bAATDTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ“¦ InstalaÃ§Ã£o de Bibliotecas"
      ],
      "metadata": {
        "id": "mUsGJgDtYfSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers fer streamlit whisper openai pillow opencv-python matplotlib seaborn"
      ],
      "metadata": {
        "id": "4QVr4sddZgQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ› ï¸ FunÃ§Ã£o para Gerar Notebook DinÃ¢mico"
      ],
      "metadata": {
        "id": "WV3XTPtWZsty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nbformat import v4 as nbf\n",
        "import os\n",
        "\n",
        "def criar_notebook(nome=\"Relatorio_Hidra\"):\n",
        "    notebook = nbf.new_notebook()\n",
        "\n",
        "    # CÃ©lula de introduÃ§Ã£o\n",
        "    intro = nbf.new_markdown_cell(\"# RelatÃ³rio AutomÃ¡tico do Sistema Hidra\\nEste notebook foi gerado automaticamente com os resultados dos mÃ³dulos multimodais.\")\n",
        "\n",
        "    # CÃ©lula de importaÃ§Ãµes\n",
        "    imports = nbf.new_code_cell(\"\"\"import matplotlib.pyplot as plt\\nimport seaborn as sns\\nimport pandas as pd\"\"\")\n",
        "\n",
        "    # CÃ©lula de resultados de Ã¡udio\n",
        "    audio_result = nbf.new_code_cell(\"\"\"# Resultado do mÃ³dulo Whisper\\nprint('TranscriÃ§Ã£o de Ã¡udio: ...')\"\"\")\n",
        "\n",
        "    # CÃ©lula de emoÃ§Ãµes\n",
        "    emocao_result = nbf.new_code_cell(\"\"\"# Resultado do mÃ³dulo FER+\\nprint('EmoÃ§Ã£o detectada: ...')\"\"\")\n",
        "\n",
        "    # CÃ©lula de geraÃ§Ã£o de texto\n",
        "    texto_result = nbf.new_code_cell(\"\"\"# Resultado do mÃ³dulo Hidra Instruct\\nprint('Texto gerado: ...')\"\"\")\n",
        "\n",
        "    # CÃ©lula de anÃ¡lise preditiva\n",
        "    cygnus_result = nbf.new_code_cell(\"\"\"# Resultado do mÃ³dulo Cygnus\\nprint('AnÃ¡lise preditiva: ...')\"\"\")\n",
        "\n",
        "    # CÃ©lula de conclusÃ£o\n",
        "    conclusao = nbf.new_markdown_cell(\"## ConclusÃ£o\\nEste relatÃ³rio consolida os dados multimodais processados pelo sistema Hidra, promovendo explicabilidade e responsabilidade.\")\n",
        "\n",
        "    # Adiciona todas as cÃ©lulas\n",
        "    notebook.cells = [intro, imports, audio_result, emocao_result, texto_result, cygnus_result, conclusao]\n",
        "\n",
        "    # Salva o notebook\n",
        "    with open(f\"{nome}.ipynb\", \"w\", encoding=\"utf-8\") as f:\n",
        "        nbf.write(notebook, f)\n",
        "\n",
        "    print(f\"Notebook '{nome}.ipynb' criado com sucesso.\")"
      ],
      "metadata": {
        "id": "7-bifo3qZupB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ“˜ Estrutura do Notebook Colab â€“ IntegraÃ§Ã£o do Sistema Hidra\n",
        "\n",
        " ğŸ”§ 1. InstalaÃ§Ã£o de Bibliotecas"
      ],
      "metadata": {
        "id": "6AHN9PfhZ09_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers fer whisper openai pillow opencv-python matplotlib seaborn requests"
      ],
      "metadata": {
        "id": "FxIl6PkMaBxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ§  2. MÃ³dulo Cygnus â€“ ExecuÃ§Ã£o Preditiva"
      ],
      "metadata": {
        "id": "pTPAbjKkaEfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gemini import AdvancedModel\n",
        "\n",
        "# SimulaÃ§Ã£o de dados de entrada\n",
        "input_data = {\n",
        "    \"temperatura\": [22.5, 23.0, 24.1, 25.3],\n",
        "    \"umidade\": [60, 58, 55, 53]\n",
        "}\n",
        "\n",
        "# Carregando o modelo Cygnus\n",
        "model = AdvancedModel.load(\"cygnus-ultimate\")\n",
        "\n",
        "# Configurando parÃ¢metros avanÃ§ados\n",
        "model.configure(precision=\"float16\", optimization_level=3)\n",
        "\n",
        "# Executando tarefa preditiva\n",
        "result = model.execute_task(\"anÃ¡lise preditiva\", data=input_data)\n",
        "print(\"Resultado da anÃ¡lise preditiva:\", result)"
      ],
      "metadata": {
        "id": "FHrJ6baAaGOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ“Š 3. VisualizaÃ§Ã£o com Matplotlib e Seaborn"
      ],
      "metadata": {
        "id": "NNXtaR7kaKGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Convertendo dados simulados em DataFrame\n",
        "df = pd.DataFrame(input_data)\n",
        "\n",
        "# GrÃ¡fico de linha\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.lineplot(data=df)\n",
        "plt.title(\"SÃ©ries Temporais - Temperatura e Umidade\")\n",
        "plt.xlabel(\"Tempo\")\n",
        "plt.ylabel(\"Valor\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hYFTfXJ2aK3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸŒ 4. IntegraÃ§Ã£o com API Externa (Exemplo com OpenWeather)"
      ],
      "metadata": {
        "id": "OshhCaZJaaL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Exemplo de chamada Ã  API do OpenWeather (substitua pela sua chave)\n",
        "api_key = \"SUA_CHAVE_AQUI\"\n",
        "cidade = \"Salinas,BR\"\n",
        "url = f\"http://api.openweathermap.org/data/2.5/weather?q={cidade}&appid={api_key}&units=metric\"\n",
        "\n",
        "response = requests.get(url)\n",
        "dados = response.json()\n",
        "\n",
        "# Exibindo dados relevantes\n",
        "print(\"Temperatura atual:\", dados[\"main\"][\"temp\"], \"Â°C\")\n",
        "print(\"CondiÃ§Ãµes climÃ¡ticas:\", dados[\"weather\"][0][\"description\"])"
      ],
      "metadata": {
        "id": "EWSO24TVabYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ§ª Testando a API com Python"
      ],
      "metadata": {
        "id": "J2wf-op6kcj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_KEY = \"sua_chave_aqui\"\n",
        "url = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent\"\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
        "}\n",
        "\n",
        "data = {\n",
        "    \"contents\": [{\"parts\": [{\"text\": \"Explique o impacto da IA multimodal na educaÃ§Ã£o inclusiva.\"}]}]\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, json=data)\n",
        "print(response.json())"
      ],
      "metadata": {
        "id": "6WL2j-xbkezP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ“‘ Ãndice do Projeto Hidra\n",
        "\n",
        "- [1. Capa e IdentificaÃ§Ã£o](#1-capa-e-identificaÃ§Ã£o)\n",
        "- [2. Objetivo do Projeto](#2-objetivo-do-projeto)\n",
        "- [3. InstalaÃ§Ã£o de Bibliotecas](#3-instalaÃ§Ã£o-de-bibliotecas)\n",
        "- [4. Granite Instruct â€“ GeraÃ§Ã£o de Texto](#4-granite-instruct--geraÃ§Ã£o-de-texto)\n",
        "- [5. Granite Guardian â€“ Auditoria Ã‰tica](#5-granite-guardian--auditoria-Ã©tica)\n",
        "- [6. Granite Vision â€“ ClassificaÃ§Ã£o de Imagem](#6-granite-vision--classificaÃ§Ã£o-de-imagem)\n",
        "- [7. Whisper â€“ TranscriÃ§Ã£o de Ãudio](#7-whisper--transcriÃ§Ã£o-de-Ã¡udio)\n",
        "- [8. FER+ â€“ EmoÃ§Ãµes Faciais](#8-fer--emoÃ§Ãµes-faciais)\n",
        "- [9. Operator â€“ RaciocÃ­nio LÃ³gico](#9-operator--raciocÃ­nio-lÃ³gico)\n",
        "- [10. Interface Interativa](#10-interface-interativa)\n",
        "- [11. Upload de Arquivos](#11-upload-de-arquivos)\n",
        "- [12. ConclusÃ£o](#12-conclusÃ£o)\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Capa e IdentificaÃ§Ã£o\n",
        "\n",
        "**Discente:** Luiz Augusto Mendes Barbosa  \n",
        "**InstituiÃ§Ã£o:** Instituto Federal do Norte de Minas Gerais â€“ Campus Salinas  \n",
        "**Curso:** Bacharelado em Sistemas de InformaÃ§Ã£o\n",
        "**Data:** Julho de 2025\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Objetivo do Projeto\n",
        "\n",
        "Desenvolver um sistema de inteligÃªncia artificial multimodal baseado nos modelos IBM Granite, com foco em aplicaÃ§Ãµes educacionais, institucionais e Ã©ticas.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. InstalaÃ§Ã£o de Bibliotecas\n",
        "\n",
        "```python\n",
        "!pip install transformers fer streamlit whisper openai pillow opencv-python"
      ],
      "metadata": {
        "id": "J84pQ-J5TI7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"IBM/granite-3b-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "prompt = \"Explique os riscos Ã©ticos do uso de IA em ambientes escolares.\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = model.generate(**inputs, max_new_tokens=250)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "bMKwzEPCUsSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Criar diretÃ³rio chamado 'Streamlit'\n",
        "os.makedirs(\"Streamlit\", exist_ok=True)\n",
        "\n",
        "print(\"DiretÃ³rio 'Streamlit' criado com sucesso.\")"
      ],
      "metadata": {
        "id": "erJSVJoOU5eA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104303d1-ff6c-4f01-f09a-9283d767b7d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DiretÃ³rio 'Streamlit' criado com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ“ Criar app.py no diretÃ³rio Streamlit\n",
        "# ConteÃºdo do app Streamlit\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J6wwksD0qaUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ConteÃºdo do app Streamlit\n",
        "codigo_app = \"\"\"\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"ğŸ§  Sistema Hidra â€“ Painel Multimodal\")\n",
        "\n",
        "st.header(\"ğŸ§ TranscriÃ§Ã£o de Ãudio (Whisper)\")\n",
        "transcricao = st.text_area(\"Resultado da transcriÃ§Ã£o:\", \"TranscriÃ§Ã£o de Ã¡udio: ...\")\n",
        "\n",
        "st.header(\"ğŸ˜Š EmoÃ§Ãµes Detectadas (FER+)\")\n",
        "emocao = st.text_input(\"EmoÃ§Ã£o detectada:\", \"EmoÃ§Ã£o detectada: ...\")\n",
        "\n",
        "st.header(\"ğŸ“ GeraÃ§Ã£o de Texto (Hidra Instruct)\")\n",
        "texto = st.text_area(\"Texto gerado:\", \"Texto gerado: ...\")\n",
        "\n",
        "st.header(\"ğŸ“ˆ AnÃ¡lise Preditiva (Cygnus)\")\n",
        "previsao = st.text_input(\"PrevisÃ£o Cygnus:\", \"AnÃ¡lise preditiva: ...\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"âœ… Sistema Hidra â€“ Interface interativa para visualizaÃ§Ã£o de resultados multimodais.\")\n",
        "\"\"\"\n",
        "\n",
        "# Criar diretÃ³rio se nÃ£o existir\n",
        "import os\n",
        "os.makedirs(\"Streamlit\", exist_ok=True)\n",
        "\n",
        "# Salvar como app.py\n",
        "with open(\"Streamlit/app.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(codigo_app)\n",
        "\n",
        "print(\"Arquivo 'app.py' criado com sucesso em Streamlit/\")"
      ],
      "metadata": {
        "id": "z7at7rQfqCdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codigo_app = \"\"\" import streamlit as st\n",
        "\n",
        "# TÃ­tulo do app\n",
        "st.title(\"ğŸ§  Sistema Hidra â€“ Painel Multimodal\")\n",
        "\n",
        "# SeÃ§Ãµes principais\n",
        "st.header(\"ğŸ§ TranscriÃ§Ã£o de Ãudio (Whisper)\")\n",
        "transcricao = st.text_area(\"Resultado da transcriÃ§Ã£o:\", \"TranscriÃ§Ã£o de Ã¡udio: ...\")\n",
        "\n",
        "st.header(\"ğŸ˜Š EmoÃ§Ãµes Detectadas (FER+)\")\n",
        "emocao = st.text_input(\"EmoÃ§Ã£o detectada:\", \"EmoÃ§Ã£o detectada: ...\")\n",
        "\n",
        "st.header(\"ğŸ“ GeraÃ§Ã£o de Texto (Hidra Instruct)\")\n",
        "texto = st.text_area(\"Texto gerado:\", \"Texto gerado: ...\")\n",
        "\n",
        "st.header(\"ğŸ“ˆ AnÃ¡lise Preditiva (Cygnus)\")\n",
        "previsao = st.text_input(\"PrevisÃ£o Cygnus:\", \"AnÃ¡lise preditiva: ...\")\n",
        "\n",
        "# RodapÃ©\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"âœ… Sistema Hidra â€“ Interface interativa para visualizaÃ§Ã£o de resultados multimodais.\") \"\"\""
      ],
      "metadata": {
        "id": "hRLdt-lcpUvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codigo_app = \"\"\" import streamlit as st\n",
        "\n",
        "# TÃ­tulo do app\n",
        "st.title(\"ğŸ§  Sistema Hidra â€“ Painel Multimodal\")\n",
        "\n",
        "# SeÃ§Ãµes principais\n",
        "st.header(\"ğŸ§ TranscriÃ§Ã£o de Ãudio (Whisper)\")\n",
        "transcricao = st.text_area(\"Resultado da transcriÃ§Ã£o:\", \"TranscriÃ§Ã£o de Ã¡udio: ...\")\n",
        "\n",
        "st.header(\"ğŸ˜Š EmoÃ§Ãµes Detectadas (FER+)\")\n",
        "emocao = st.text_input(\"EmoÃ§Ã£o detectada:\", \"EmoÃ§Ã£o detectada: ...\")\n",
        "\n",
        "st.header(\"ğŸ“ GeraÃ§Ã£o de Texto (Hidra Instruct)\")\n",
        "texto = st.text_area(\"Texto gerado:\", \"Texto gerado: ...\")\n",
        "\n",
        "st.header(\"ğŸ“ˆ AnÃ¡lise Preditiva (Cygnus)\")\n",
        "previsao = st.text_input(\"PrevisÃ£o Cygnus:\", \"AnÃ¡lise preditiva: ...\")\n",
        "\n",
        "# RodapÃ©\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"âœ… Sistema Hidra â€“ Interface interativa para visualizaÃ§Ã£o de resultados multimodais.\") \"\"\"\n",
        "\n",
        "with open(\"Streamlit/app.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(codigo_app)"
      ],
      "metadata": {
        "id": "nn0KTIJ1rnnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEsqEZU-tMiw",
        "outputId": "71f099c4-f812-40e5-c19d-8320ddc3b669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.47.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading pyngrok-7.2.12-py3-none-any.whl (26 kB)\n",
            "Downloading streamlit-1.47.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.12 streamlit-1.47.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Abrir tÃºnel na porta 8501 (padrÃ£o do Streamlit)\n",
        "public_url = ngrok.connect(port=8501)\n",
        "print(\"ğŸ”— URL pÃºblica do Streamlit:\", public_url)\n",
        "\n",
        "# Rodar o app Streamlit\n",
        "!streamlit run Streamlit/app.py &"
      ],
      "metadata": {
        "id": "KIjucWBptVdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ’¡ Listar os arquivos e diretÃ³rios:\n"
      ],
      "metadata": {
        "id": "BtlpW7MVq30q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "metadata": {
        "id": "MzPct484rBA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ver conteÃºdo"
      ],
      "metadata": {
        "id": "tdDC0NPKrGF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"Streamlit\")"
      ],
      "metadata": {
        "id": "h7kxgx_6rH_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8ecb15f"
      },
      "source": [
        "!streamlit run Streamlit/app.py &>/dev/null&"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbformat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9ZQVCqTwMFO",
        "outputId": "4e0502a1-3a2e-45b0-fcb9-ba5bbb29a05e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (5.10.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat) (4.25.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat) (5.8.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.11/dist-packages (from nbformat) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat) (0.26.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.8)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nbformat import v4 as nbf\n",
        "import nbformat\n",
        "\n",
        "def criar_notebook(nome=\"Relatorio_Hidra\"):\n",
        "    notebook = nbf.new_notebook()\n",
        "\n",
        "    # CÃ©lula de introduÃ§Ã£o\n",
        "    intro = nbf.new_markdown_cell(\"# ğŸ§  RelatÃ³rio do Sistema Hidra\\nEste notebook documenta os principais mÃ³dulos e funcionalidades da IA multimodal Hidra.\")\n",
        "\n",
        "    # CÃ©lula de importaÃ§Ãµes\n",
        "    imports = nbf.new_code_cell(\"\"\"import matplotlib.pyplot as plt\\nimport seaborn as sns\\nimport pandas as pd\"\"\")\n",
        "\n",
        "    # CÃ©lula de exemplo de transcriÃ§Ã£o\n",
        "    whisper = nbf.new_code_cell(\"\"\"# ğŸ”Š MÃ³dulo Whisper\\nprint(\"TranscriÃ§Ã£o de Ã¡udio: O aluno demonstrou interesse no tema.\")\"\"\")\n",
        "\n",
        "    # CÃ©lula de exemplo de emoÃ§Ã£o\n",
        "    fer = nbf.new_code_cell(\"\"\"# ğŸ˜Š MÃ³dulo FER+\\nprint(\"EmoÃ§Ã£o detectada: Felicidade\")\"\"\")\n",
        "\n",
        "    # CÃ©lula de geraÃ§Ã£o de texto\n",
        "    instruct = nbf.new_code_cell(\"\"\"# ğŸ“ MÃ³dulo Hidra Instruct\\nprint(\"Texto gerado: A IA deve ser usada com responsabilidade em ambientes escolares.\")\"\"\")\n",
        "\n",
        "    # CÃ©lula de anÃ¡lise preditiva\n",
        "    cygnus = nbf.new_code_cell(\"\"\"# ğŸ“ˆ MÃ³dulo Cygnus\\nprint(\"PrevisÃ£o de temperatura: 26.3 Â°C\")\"\"\")\n",
        "\n",
        "    # Adiciona todas as cÃ©lulas\n",
        "    notebook.cells = [intro, imports, whisper, fer, instruct, cygnus]\n",
        "\n",
        "    # Salva o notebook\n",
        "    with open(f\"{nome}.ipynb\", \"w\", encoding=\"utf-8\") as f:\n",
        "        nbformat.write(notebook, f)\n",
        "\n",
        "    print(f\"âœ… Notebook '{nome}.ipynb' criado com sucesso!\")\n",
        "\n",
        "# Executar a funÃ§Ã£o\n",
        "criar_notebook()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "xI6-CKD8wlCz",
        "outputId": "420ce02a-0c1c-4426-e147-52f7dd5e0c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'nbformat.v4' has no attribute 'write'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-982491195.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Executar a funÃ§Ã£o\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mcriar_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-982491195.py\u001b[0m in \u001b[0;36mcriar_notebook\u001b[0;34m(nome)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Salva o notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{nome}.ipynb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mnbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"âœ… Notebook '{nome}.ipynb' criado com sucesso!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'nbformat.v4' has no attribute 'write'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7704cd8",
        "outputId": "d5073399-620e-4e28-f5e4-d909efe6a58d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relatorio_Hidra.ipynb  sample_data  Streamlit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"Relatorio_Hidra.ipynb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lCXbi2OJwrM6",
        "outputId": "e0cb2731-9da9-4576-93fa-ffb7b46c8af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c9015f5e-8821-4b03-8789-d826d6224567\", \"Relatorio_Hidra.ipynb\", 0)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Fzd9xVtTJvLT"
      }
    }
  ]
}