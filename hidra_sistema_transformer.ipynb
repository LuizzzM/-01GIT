{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNI/ra7+/PO95pO0dChfd2y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuizzzM/-01GIT/blob/main/hidra_sistema_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Adicionar aspas\n",
        "# üß† Notebook: Sistema Hidra ‚Äì IA Multimodal com Modelos Granite\n",
        "üìò 1. Capa e Identifica√ß√£\n"
      ],
      "metadata": {
        "id": "ifSkkHaeRUND"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N7V-quARA5j"
      },
      "outputs": [],
      "source": [
        "# Sistema Hidra ‚Äì IA Multimodal com Modelos Granite\n",
        "**Discente:** Luiz Augusto Mendes Barbosa\n",
        "**Institui√ß√£o:** Instituto Federal do Norte de Minas Gerais ‚Äì Campus Salinas\n",
        "**Curso:** Bacharelado em Sistemas de Informa√ß√£o.\n",
        "**Data:** Agosto de 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivo\n",
        "\n",
        "# Desenvolver um sistema de intelig√™ncia artificial multimodal baseado nos modelos IBM Granite, com foco em aplica√ß√µes educacionais, institucionais e √©ticas."
      ],
      "metadata": {
        "id": "5xT9Utb3Rlpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers fer streamlit whisper openai pillow opencv-python"
      ],
      "metadata": {
        "id": "4b6YnAyQTyS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß† 4. HidraText ‚Äì Gera√ß√£o de Texto Explicativo"
      ],
      "metadata": {
        "id": "YG1rTenwSMAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"IBM/granite-3b-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "prompt = \"Explique os riscos √©ticos do uso de IA em ambientes escolares.\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = model.generate(**inputs, max_new_tokens=250)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "LIK_Ok7BSP3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üõ°Ô∏è 5. Hidra Guardian ‚Äì Auditoria √âtica Simulada"
      ],
      "metadata": {
        "id": "Fnj-McK-SR-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simular_auditoria(prompt_texto):\n",
        "    if \"emo√ß√£o\" in prompt_texto.lower() or \"consentimento\" in prompt_texto.lower():\n",
        "        print(\"‚ö†Ô∏è Risco √©tico detectado: Recomenda-se supervis√£o humana.\")\n",
        "    else:\n",
        "        print(\"‚úÖ Entrada validada: sem risco identificado.\")\n",
        "\n",
        "simular_auditoria(\"A IA pode monitorar emo√ß√µes sem consentimento?\")"
      ],
      "metadata": {
        "id": "pgJYtxTsSVN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üñºÔ∏è 6. Granite Vision ‚Äì Classifica√ß√£o de Imagem\n",
        "\n"
      ],
      "metadata": {
        "id": "LZa0eyYLSZ8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor, AutoModelForImageClassification\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "model_id = \"IBM/granite-vision-3.2-2b\"\n",
        "image = Image.open(requests.get(\"https://images.unsplash.com/photo-1607746882042-944635dfe10e\", stream=True).raw)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "model = AutoModelForImageClassification.from_pretrained(model_id)\n",
        "\n",
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "print(\"üñºÔ∏è Classe prevista:\", outputs.logits.argmax().item())"
      ],
      "metadata": {
        "id": "O2n_W2THSf8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîä 7. Whisper ‚Äì Transcri√ß√£o de √Åudio"
      ],
      "metadata": {
        "id": "98-CvMyBSjGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "modelo = whisper.load_model(\"base\")\n",
        "resultado = modelo.transcribe(\"caminho_para_audio.wav\")\n",
        "print(\"üó£Ô∏è Transcri√ß√£o:\", resultado[\"text\"])"
      ],
      "metadata": {
        "id": "eoytgYBcSlWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üòê 8. FER+ ‚Äì Reconhecimento de Emo√ß√µes Faciais"
      ],
      "metadata": {
        "id": "TAzctHY8Spuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fer import FER\n",
        "import cv2\n",
        "\n",
        "imagem = cv2.imread(\"expressao_usuario.jpg\")\n",
        "detector = FER(mtcnn=True)\n",
        "emocao = detector.detect_emotions(imagem)\n",
        "print(\"üòä Emo√ß√µes detectadas:\", emocao)"
      ],
      "metadata": {
        "id": "0iG5BCaNSrRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß† 9. Operator ‚Äì Racioc√≠nio L√≥gic"
      ],
      "metadata": {
        "id": "6ADNI2WTSujP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_id = \"Operator/logic-integration-1b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
        "\n",
        "inputs = tokenizer(\"Analise os dados e gere sugest√µes.\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "print(\"üîç Sugest√£o l√≥gica (classe):\", outputs.logits.argmax().item())"
      ],
      "metadata": {
        "id": "2J4PqqpmSx-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üñ•Ô∏è 10. Interface Interativa com Widgets (Opcional)"
      ],
      "metadata": {
        "id": "PYQ9Pdk3S0P5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "entrada = widgets.Text(value='', placeholder='Digite sua pergunta', description='Pergunta:')\n",
        "display(entrada)"
      ],
      "metadata": {
        "id": "DURgw8nhS3xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìÇ 11. Upload de Arquivos\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "\n",
        "üìò 12. Conclus√£o\n",
        "## Conclus√£o\n",
        "\n",
        "O sistema Hidra demonstra a viabilidade de integrar modelos multimodais com foco em √©tica, explicabilidade e aplicabilidade educacional. A arquitetura modular e o uso dos modelos Granite garantem robustez e transpar√™ncia, enquanto os m√≥dulos complementares ampliam o repert√≥rio t√©cnico e acad√™mico.\n",
        "\n",
        "Ó∑ôÓ∑ö\n",
        "\n",
        "Se quiser, posso montar esse conte√∫do como um √≠ndice interativo ou sugerir como dividir em se√ß√µes com links internos no Colab. Deseja que eu prepare isso tamb√©m? üìòüß†üìÇ\n"
      ],
      "metadata": {
        "id": "ti5IqTfeS-H4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "2pfD2bAATDTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìë √çndice do Projeto Hidra\n",
        "\n",
        "- [1. Capa e Identifica√ß√£o](#1-capa-e-identifica√ß√£o)\n",
        "- [2. Objetivo do Projeto](#2-objetivo-do-projeto)\n",
        "- [3. Instala√ß√£o de Bibliotecas](#3-instala√ß√£o-de-bibliotecas)\n",
        "- [4. Granite Instruct ‚Äì Gera√ß√£o de Texto](#4-granite-instruct--gera√ß√£o-de-texto)\n",
        "- [5. Granite Guardian ‚Äì Auditoria √âtica](#5-granite-guardian--auditoria-√©tica)\n",
        "- [6. Granite Vision ‚Äì Classifica√ß√£o de Imagem](#6-granite-vision--classifica√ß√£o-de-imagem)\n",
        "- [7. Whisper ‚Äì Transcri√ß√£o de √Åudio](#7-whisper--transcri√ß√£o-de-√°udio)\n",
        "- [8. FER+ ‚Äì Emo√ß√µes Faciais](#8-fer--emo√ß√µes-faciais)\n",
        "- [9. Operator ‚Äì Racioc√≠nio L√≥gico](#9-operator--racioc√≠nio-l√≥gico)\n",
        "- [10. Interface Interativa](#10-interface-interativa)\n",
        "- [11. Upload de Arquivos](#11-upload-de-arquivos)\n",
        "- [12. Conclus√£o](#12-conclus√£o)\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Capa e Identifica√ß√£o\n",
        "\n",
        "**Discente:** Luiz Augusto Mendes Barbosa  \n",
        "**Institui√ß√£o:** Instituto Federal do Norte de Minas Gerais ‚Äì Campus Salinas  \n",
        "**Curso:** Bacharelado em sistemas de informa√ß√£o\n",
        "**Data:** Agosto de 2025\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Objetivo do Projeto\n",
        "\n",
        "Desenvolver um sistema de intelig√™ncia artificial multimodal baseado nos modelos IBM Granite, com foco em aplica√ß√µes educacionais, institucionais e √©ticas.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Instala√ß√£o de Bibliotecas\n",
        "\n",
        "```python\n",
        "!pip install transformers fer streamlit whisper openai pillow opencv-python"
      ],
      "metadata": {
        "id": "J84pQ-J5TI7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Granite Instruct ‚Äì Gera√ß√£o de Texto"
      ],
      "metadata": {
        "id": "JFXhL2ljUqYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"IBM/granite-3b-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "prompt = \"Explique os riscos √©ticos do uso de IA em ambientes escolares.\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = model.generate(**inputs, max_new_tokens=250)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "bMKwzEPCUsSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### üíª Bloco de C√≥digo ‚Äî Criar Notebook Programaticamente (Avan√ßado)\n",
        "\n",
        "Se quiser gerar o notebook `.ipynb` automaticamente com Python, voc√™ pode usar este script localmente (n√£o no Colab):\n",
        "\n",
        "```python\n",
        "import nbformat as nbf\n",
        "\n",
        "# Cria novo notebook\n",
        "notebook = nbf.v4.new_notebook()\n",
        "\n",
        "# C√©lulas de texto e c√≥digo\n",
        "cells = [\n",
        "    nbf.v4.new_markdown_cell(\"# Sistema Hidra ‚Äì IA Multimodal\\nDiscente: Luiz Augusto Mendes Barbosa\"),\n",
        "    nbf.v4.new_markdown_cell(\"## Objetivo\\nDesenvolver um sistema multimodal com base nos modelos Granite.\"),\n",
        "    nbf.v4.new_code_cell(\"!pip install transformers fer streamlit whisper openai pillow opencv-python\"),\n",
        "    nbf.v4.new_code_cell(\"\"\"from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "model_id = \"IBM/granite-3b-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "prompt = \"Explique os riscos √©ticos do uso de IA em ambientes escolares.\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = model.generate(**inputs, max_new_tokens=250)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))\"\"\")\n",
        "]\n",
        "\n",
        "notebook['cells'] = cells\n",
        "\n",
        "# Salva como arquivo .ipynb\n",
        "with open(\"hidra_sistema_transformer.ipynb\", \"w\", encoding=\"utf-8\") as f:\n",
        "    nbf.write(notebook, f)"
      ],
      "metadata": {
        "id": "erJSVJoOU5eA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}